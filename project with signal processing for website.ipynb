{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5679d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#keras\n",
    "import keras\n",
    "from keras import layers \n",
    "from keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27aa9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder, scale, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D, UpSampling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l1\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "import librosa, librosa.display, os, csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "plt.switch_backend('agg')\n",
    "import itertools\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "import joblib\n",
    "from glob import glob\n",
    "import urllib\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56096474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_properties</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/Corona folder/srikanth corona project/trial...</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/Corona folder/srikanth corona project/trial...</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/Corona folder/srikanth corona project/trial...</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/Corona folder/srikanth corona project/trial...</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/Corona folder/srikanth corona project/trial...</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>D:/Corona folder/srikanth corona project/trial...</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>D:/Corona folder/srikanth corona project/trial...</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>D:/Corona folder/srikanth corona project/trial...</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>D:/Corona folder/srikanth corona project/trial...</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>D:/Corona folder/srikanth corona project/trial...</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file_properties      class\n",
       "0    D:/Corona folder/srikanth corona project/trial...  not_covid\n",
       "1    D:/Corona folder/srikanth corona project/trial...  not_covid\n",
       "2    D:/Corona folder/srikanth corona project/trial...  not_covid\n",
       "3    D:/Corona folder/srikanth corona project/trial...  not_covid\n",
       "4    D:/Corona folder/srikanth corona project/trial...      covid\n",
       "..                                                 ...        ...\n",
       "165  D:/Corona folder/srikanth corona project/trial...  not_covid\n",
       "166  D:/Corona folder/srikanth corona project/trial...  not_covid\n",
       "167  D:/Corona folder/srikanth corona project/trial...  not_covid\n",
       "168  D:/Corona folder/srikanth corona project/trial...  not_covid\n",
       "169  D:/Corona folder/srikanth corona project/trial...  not_covid\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('D:\\Corona folder\\srikanth corona project\\cough_trial_extended.csv')\n",
    "train_csv['file_properties']='D:/Corona folder/srikanth corona project/trial_covid/'+train_csv['file_properties']\n",
    "train_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b06eaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.indexing._iLocIndexer at 0x1c9710d3f40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tf=pd.read_csv(r'D:\\Corona folder\\srikanth corona project\\covid_dataset.csv')\n",
    "tf['filename']=r'D:/Corona folder/srikanth corona project/trial_covid/'+tf['filename']\n",
    "tf1=tf.iloc[:,0:1]\n",
    "tf2=tf.iloc[:,28:29]\n",
    "tf2\n",
    "TF=tf1.join(tf2)\n",
    "TF\n",
    "TF.rename(columns={'filename':'file_properties','label':'class'},inplace=True)\n",
    "TF\n",
    "data=pd.concat((train_csv,TF),axis=0,join='outer',ignore_index=True)\n",
    "data['class'].replace({'positive':'covid','negative':'not_covid'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff56c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 41):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f319ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file = open('obtained_values.csv', 'w')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "for i ,j in data.iterrows():\n",
    "    file_name=j['file_properties']\n",
    "    lab=j['class']\n",
    "    y,sr = librosa.load(file_name, mono=True, duration=5)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=40)\n",
    "    to_append = f'{file_name[56:66]} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    to_append +=f' {lab}'\n",
    "    \n",
    "    \n",
    "    file = open('obtained_values.csv', 'a')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0094055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc32</th>\n",
       "      <th>mfcc33</th>\n",
       "      <th>mfcc34</th>\n",
       "      <th>mfcc35</th>\n",
       "      <th>mfcc36</th>\n",
       "      <th>mfcc37</th>\n",
       "      <th>mfcc38</th>\n",
       "      <th>mfcc39</th>\n",
       "      <th>mfcc40</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGxNetjg_</td>\n",
       "      <td>0.519951</td>\n",
       "      <td>0.045853</td>\n",
       "      <td>1612.895795</td>\n",
       "      <td>1411.838677</td>\n",
       "      <td>2907.580566</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>-376.876007</td>\n",
       "      <td>111.017372</td>\n",
       "      <td>-31.904013</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.276272</td>\n",
       "      <td>-0.625641</td>\n",
       "      <td>-1.608061</td>\n",
       "      <td>-1.412680</td>\n",
       "      <td>-0.594154</td>\n",
       "      <td>-2.270374</td>\n",
       "      <td>-1.230999</td>\n",
       "      <td>-1.667140</td>\n",
       "      <td>-0.667805</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>duoxdxBg_</td>\n",
       "      <td>0.535472</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>2892.087076</td>\n",
       "      <td>2467.408141</td>\n",
       "      <td>5072.664388</td>\n",
       "      <td>0.148584</td>\n",
       "      <td>-519.158447</td>\n",
       "      <td>60.781284</td>\n",
       "      <td>-13.722886</td>\n",
       "      <td>...</td>\n",
       "      <td>1.927568</td>\n",
       "      <td>-2.116628</td>\n",
       "      <td>1.253289</td>\n",
       "      <td>-2.312178</td>\n",
       "      <td>1.540753</td>\n",
       "      <td>-3.853856</td>\n",
       "      <td>1.536122</td>\n",
       "      <td>-3.761888</td>\n",
       "      <td>0.968226</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YO4wgiag_</td>\n",
       "      <td>0.496666</td>\n",
       "      <td>0.033657</td>\n",
       "      <td>3429.061935</td>\n",
       "      <td>2788.634413</td>\n",
       "      <td>6886.288452</td>\n",
       "      <td>0.225315</td>\n",
       "      <td>-282.297913</td>\n",
       "      <td>48.581680</td>\n",
       "      <td>-15.522366</td>\n",
       "      <td>...</td>\n",
       "      <td>2.145280</td>\n",
       "      <td>-2.767728</td>\n",
       "      <td>0.227271</td>\n",
       "      <td>-2.796792</td>\n",
       "      <td>-0.805099</td>\n",
       "      <td>-2.301651</td>\n",
       "      <td>0.147189</td>\n",
       "      <td>-1.996069</td>\n",
       "      <td>2.062976</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jbAKd8Kg_</td>\n",
       "      <td>0.407549</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>2710.811637</td>\n",
       "      <td>2664.287550</td>\n",
       "      <td>5778.474935</td>\n",
       "      <td>0.142076</td>\n",
       "      <td>-346.857300</td>\n",
       "      <td>75.765617</td>\n",
       "      <td>-7.648193</td>\n",
       "      <td>...</td>\n",
       "      <td>1.614948</td>\n",
       "      <td>-1.242405</td>\n",
       "      <td>-1.523256</td>\n",
       "      <td>-4.805856</td>\n",
       "      <td>-1.141960</td>\n",
       "      <td>-2.236271</td>\n",
       "      <td>-2.583130</td>\n",
       "      <td>-5.340420</td>\n",
       "      <td>-2.442520</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.wav</td>\n",
       "      <td>0.412697</td>\n",
       "      <td>0.059004</td>\n",
       "      <td>1555.648634</td>\n",
       "      <td>1418.599932</td>\n",
       "      <td>2870.737092</td>\n",
       "      <td>0.133998</td>\n",
       "      <td>-340.588013</td>\n",
       "      <td>104.156700</td>\n",
       "      <td>-32.228443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151529</td>\n",
       "      <td>-1.332800</td>\n",
       "      <td>-0.106066</td>\n",
       "      <td>0.582513</td>\n",
       "      <td>-0.861203</td>\n",
       "      <td>0.320628</td>\n",
       "      <td>1.574154</td>\n",
       "      <td>0.413459</td>\n",
       "      <td>0.444616</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>a/negative</td>\n",
       "      <td>0.417148</td>\n",
       "      <td>0.045211</td>\n",
       "      <td>2369.938534</td>\n",
       "      <td>2067.716183</td>\n",
       "      <td>4717.735662</td>\n",
       "      <td>0.154040</td>\n",
       "      <td>-282.171326</td>\n",
       "      <td>88.513092</td>\n",
       "      <td>-18.037218</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.575409</td>\n",
       "      <td>0.186341</td>\n",
       "      <td>2.064215</td>\n",
       "      <td>0.425656</td>\n",
       "      <td>-1.561547</td>\n",
       "      <td>-0.249007</td>\n",
       "      <td>-1.009573</td>\n",
       "      <td>-2.299492</td>\n",
       "      <td>-1.826561</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>a/negative</td>\n",
       "      <td>0.480541</td>\n",
       "      <td>0.046763</td>\n",
       "      <td>2179.220385</td>\n",
       "      <td>2173.195343</td>\n",
       "      <td>4751.847634</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>-359.640625</td>\n",
       "      <td>75.772011</td>\n",
       "      <td>7.082318</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.771891</td>\n",
       "      <td>-1.599745</td>\n",
       "      <td>-1.263624</td>\n",
       "      <td>0.775504</td>\n",
       "      <td>2.339190</td>\n",
       "      <td>1.845072</td>\n",
       "      <td>2.218437</td>\n",
       "      <td>0.752891</td>\n",
       "      <td>-1.126326</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>a/negative</td>\n",
       "      <td>0.451153</td>\n",
       "      <td>0.040309</td>\n",
       "      <td>1640.506731</td>\n",
       "      <td>1916.351137</td>\n",
       "      <td>3635.990574</td>\n",
       "      <td>0.058771</td>\n",
       "      <td>-392.291321</td>\n",
       "      <td>83.491142</td>\n",
       "      <td>12.452518</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.041149</td>\n",
       "      <td>-0.279625</td>\n",
       "      <td>0.884969</td>\n",
       "      <td>-0.188822</td>\n",
       "      <td>-0.359877</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>0.041764</td>\n",
       "      <td>-0.197566</td>\n",
       "      <td>-0.147689</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>a/negative</td>\n",
       "      <td>0.507765</td>\n",
       "      <td>0.047907</td>\n",
       "      <td>2289.873618</td>\n",
       "      <td>2244.929191</td>\n",
       "      <td>5017.055377</td>\n",
       "      <td>0.127125</td>\n",
       "      <td>-360.749054</td>\n",
       "      <td>82.124313</td>\n",
       "      <td>4.179862</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.998783</td>\n",
       "      <td>-1.678998</td>\n",
       "      <td>-0.865947</td>\n",
       "      <td>-0.499135</td>\n",
       "      <td>1.030186</td>\n",
       "      <td>1.320255</td>\n",
       "      <td>1.051911</td>\n",
       "      <td>0.523360</td>\n",
       "      <td>-0.475488</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>a/negative</td>\n",
       "      <td>0.546504</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>1756.939071</td>\n",
       "      <td>1920.931232</td>\n",
       "      <td>3803.399291</td>\n",
       "      <td>0.069695</td>\n",
       "      <td>-391.126282</td>\n",
       "      <td>84.532150</td>\n",
       "      <td>-7.056905</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.142547</td>\n",
       "      <td>-0.036875</td>\n",
       "      <td>-0.463881</td>\n",
       "      <td>-1.210340</td>\n",
       "      <td>-2.041662</td>\n",
       "      <td>-0.094271</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>-0.393657</td>\n",
       "      <td>-0.438716</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename  chroma_stft      rmse  spectral_centroid  spectral_bandwidth  \\\n",
       "0     MGxNetjg_     0.519951  0.045853        1612.895795         1411.838677   \n",
       "1     duoxdxBg_     0.535472  0.001771        2892.087076         2467.408141   \n",
       "2     YO4wgiag_     0.496666  0.033657        3429.061935         2788.634413   \n",
       "3     jbAKd8Kg_     0.407549  0.013452        2710.811637         2664.287550   \n",
       "4         1.wav     0.412697  0.059004        1555.648634         1418.599932   \n",
       "..          ...          ...       ...                ...                 ...   \n",
       "633  a/negative     0.417148  0.045211        2369.938534         2067.716183   \n",
       "634  a/negative     0.480541  0.046763        2179.220385         2173.195343   \n",
       "635  a/negative     0.451153  0.040309        1640.506731         1916.351137   \n",
       "636  a/negative     0.507765  0.047907        2289.873618         2244.929191   \n",
       "637  a/negative     0.546504  0.030731        1756.939071         1920.931232   \n",
       "\n",
       "         rolloff  zero_crossing_rate       mfcc1       mfcc2      mfcc3  ...  \\\n",
       "0    2907.580566            0.107019 -376.876007  111.017372 -31.904013  ...   \n",
       "1    5072.664388            0.148584 -519.158447   60.781284 -13.722886  ...   \n",
       "2    6886.288452            0.225315 -282.297913   48.581680 -15.522366  ...   \n",
       "3    5778.474935            0.142076 -346.857300   75.765617  -7.648193  ...   \n",
       "4    2870.737092            0.133998 -340.588013  104.156700 -32.228443  ...   \n",
       "..           ...                 ...         ...         ...        ...  ...   \n",
       "633  4717.735662            0.154040 -282.171326   88.513092 -18.037218  ...   \n",
       "634  4751.847634            0.116623 -359.640625   75.772011   7.082318  ...   \n",
       "635  3635.990574            0.058771 -392.291321   83.491142  12.452518  ...   \n",
       "636  5017.055377            0.127125 -360.749054   82.124313   4.179862  ...   \n",
       "637  3803.399291            0.069695 -391.126282   84.532150  -7.056905  ...   \n",
       "\n",
       "       mfcc32    mfcc33    mfcc34    mfcc35    mfcc36    mfcc37    mfcc38  \\\n",
       "0   -2.276272 -0.625641 -1.608061 -1.412680 -0.594154 -2.270374 -1.230999   \n",
       "1    1.927568 -2.116628  1.253289 -2.312178  1.540753 -3.853856  1.536122   \n",
       "2    2.145280 -2.767728  0.227271 -2.796792 -0.805099 -2.301651  0.147189   \n",
       "3    1.614948 -1.242405 -1.523256 -4.805856 -1.141960 -2.236271 -2.583130   \n",
       "4   -0.151529 -1.332800 -0.106066  0.582513 -0.861203  0.320628  1.574154   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "633 -4.575409  0.186341  2.064215  0.425656 -1.561547 -0.249007 -1.009573   \n",
       "634 -2.771891 -1.599745 -1.263624  0.775504  2.339190  1.845072  2.218437   \n",
       "635 -1.041149 -0.279625  0.884969 -0.188822 -0.359877 -0.033061  0.041764   \n",
       "636 -2.998783 -1.678998 -0.865947 -0.499135  1.030186  1.320255  1.051911   \n",
       "637 -1.142547 -0.036875 -0.463881 -1.210340 -2.041662 -0.094271  0.005632   \n",
       "\n",
       "       mfcc39    mfcc40      label  \n",
       "0   -1.667140 -0.667805  not_covid  \n",
       "1   -3.761888  0.968226  not_covid  \n",
       "2   -1.996069  2.062976  not_covid  \n",
       "3   -5.340420 -2.442520  not_covid  \n",
       "4    0.413459  0.444616      covid  \n",
       "..        ...       ...        ...  \n",
       "633 -2.299492 -1.826561  not_covid  \n",
       "634  0.752891 -1.126326  not_covid  \n",
       "635 -0.197566 -0.147689  not_covid  \n",
       "636  0.523360 -0.475488  not_covid  \n",
       "637 -0.393657 -0.438716  not_covid  \n",
       "\n",
       "[638 rows x 48 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('obtained_values.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91934436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20a678b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc32</th>\n",
       "      <th>mfcc33</th>\n",
       "      <th>mfcc34</th>\n",
       "      <th>mfcc35</th>\n",
       "      <th>mfcc36</th>\n",
       "      <th>mfcc37</th>\n",
       "      <th>mfcc38</th>\n",
       "      <th>mfcc39</th>\n",
       "      <th>mfcc40</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.519951</td>\n",
       "      <td>0.045853</td>\n",
       "      <td>1612.895795</td>\n",
       "      <td>1411.838677</td>\n",
       "      <td>2907.580566</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>-376.876007</td>\n",
       "      <td>111.017372</td>\n",
       "      <td>-31.904013</td>\n",
       "      <td>6.622254</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.276272</td>\n",
       "      <td>-0.625641</td>\n",
       "      <td>-1.608061</td>\n",
       "      <td>-1.412680</td>\n",
       "      <td>-0.594154</td>\n",
       "      <td>-2.270374</td>\n",
       "      <td>-1.230999</td>\n",
       "      <td>-1.667140</td>\n",
       "      <td>-0.667805</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535472</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>2892.087076</td>\n",
       "      <td>2467.408141</td>\n",
       "      <td>5072.664388</td>\n",
       "      <td>0.148584</td>\n",
       "      <td>-519.158447</td>\n",
       "      <td>60.781284</td>\n",
       "      <td>-13.722886</td>\n",
       "      <td>52.145428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.927568</td>\n",
       "      <td>-2.116628</td>\n",
       "      <td>1.253289</td>\n",
       "      <td>-2.312178</td>\n",
       "      <td>1.540753</td>\n",
       "      <td>-3.853856</td>\n",
       "      <td>1.536122</td>\n",
       "      <td>-3.761888</td>\n",
       "      <td>0.968226</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.496666</td>\n",
       "      <td>0.033657</td>\n",
       "      <td>3429.061935</td>\n",
       "      <td>2788.634413</td>\n",
       "      <td>6886.288452</td>\n",
       "      <td>0.225315</td>\n",
       "      <td>-282.297913</td>\n",
       "      <td>48.581680</td>\n",
       "      <td>-15.522366</td>\n",
       "      <td>12.710722</td>\n",
       "      <td>...</td>\n",
       "      <td>2.145280</td>\n",
       "      <td>-2.767728</td>\n",
       "      <td>0.227271</td>\n",
       "      <td>-2.796792</td>\n",
       "      <td>-0.805099</td>\n",
       "      <td>-2.301651</td>\n",
       "      <td>0.147189</td>\n",
       "      <td>-1.996069</td>\n",
       "      <td>2.062976</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407549</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>2710.811637</td>\n",
       "      <td>2664.287550</td>\n",
       "      <td>5778.474935</td>\n",
       "      <td>0.142076</td>\n",
       "      <td>-346.857300</td>\n",
       "      <td>75.765617</td>\n",
       "      <td>-7.648193</td>\n",
       "      <td>11.362121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.614948</td>\n",
       "      <td>-1.242405</td>\n",
       "      <td>-1.523256</td>\n",
       "      <td>-4.805856</td>\n",
       "      <td>-1.141960</td>\n",
       "      <td>-2.236271</td>\n",
       "      <td>-2.583130</td>\n",
       "      <td>-5.340420</td>\n",
       "      <td>-2.442520</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.412697</td>\n",
       "      <td>0.059004</td>\n",
       "      <td>1555.648634</td>\n",
       "      <td>1418.599932</td>\n",
       "      <td>2870.737092</td>\n",
       "      <td>0.133998</td>\n",
       "      <td>-340.588013</td>\n",
       "      <td>104.156700</td>\n",
       "      <td>-32.228443</td>\n",
       "      <td>-13.615362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151529</td>\n",
       "      <td>-1.332800</td>\n",
       "      <td>-0.106066</td>\n",
       "      <td>0.582513</td>\n",
       "      <td>-0.861203</td>\n",
       "      <td>0.320628</td>\n",
       "      <td>1.574154</td>\n",
       "      <td>0.413459</td>\n",
       "      <td>0.444616</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.417148</td>\n",
       "      <td>0.045211</td>\n",
       "      <td>2369.938534</td>\n",
       "      <td>2067.716183</td>\n",
       "      <td>4717.735662</td>\n",
       "      <td>0.154040</td>\n",
       "      <td>-282.171326</td>\n",
       "      <td>88.513092</td>\n",
       "      <td>-18.037218</td>\n",
       "      <td>37.392307</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.575409</td>\n",
       "      <td>0.186341</td>\n",
       "      <td>2.064215</td>\n",
       "      <td>0.425656</td>\n",
       "      <td>-1.561547</td>\n",
       "      <td>-0.249007</td>\n",
       "      <td>-1.009573</td>\n",
       "      <td>-2.299492</td>\n",
       "      <td>-1.826561</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.480541</td>\n",
       "      <td>0.046763</td>\n",
       "      <td>2179.220385</td>\n",
       "      <td>2173.195343</td>\n",
       "      <td>4751.847634</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>-359.640625</td>\n",
       "      <td>75.772011</td>\n",
       "      <td>7.082318</td>\n",
       "      <td>-0.163865</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.771891</td>\n",
       "      <td>-1.599745</td>\n",
       "      <td>-1.263624</td>\n",
       "      <td>0.775504</td>\n",
       "      <td>2.339190</td>\n",
       "      <td>1.845072</td>\n",
       "      <td>2.218437</td>\n",
       "      <td>0.752891</td>\n",
       "      <td>-1.126326</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.451153</td>\n",
       "      <td>0.040309</td>\n",
       "      <td>1640.506731</td>\n",
       "      <td>1916.351137</td>\n",
       "      <td>3635.990574</td>\n",
       "      <td>0.058771</td>\n",
       "      <td>-392.291321</td>\n",
       "      <td>83.491142</td>\n",
       "      <td>12.452518</td>\n",
       "      <td>31.852299</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.041149</td>\n",
       "      <td>-0.279625</td>\n",
       "      <td>0.884969</td>\n",
       "      <td>-0.188822</td>\n",
       "      <td>-0.359877</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>0.041764</td>\n",
       "      <td>-0.197566</td>\n",
       "      <td>-0.147689</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.507765</td>\n",
       "      <td>0.047907</td>\n",
       "      <td>2289.873618</td>\n",
       "      <td>2244.929191</td>\n",
       "      <td>5017.055377</td>\n",
       "      <td>0.127125</td>\n",
       "      <td>-360.749054</td>\n",
       "      <td>82.124313</td>\n",
       "      <td>4.179862</td>\n",
       "      <td>1.507247</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.998783</td>\n",
       "      <td>-1.678998</td>\n",
       "      <td>-0.865947</td>\n",
       "      <td>-0.499135</td>\n",
       "      <td>1.030186</td>\n",
       "      <td>1.320255</td>\n",
       "      <td>1.051911</td>\n",
       "      <td>0.523360</td>\n",
       "      <td>-0.475488</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0.546504</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>1756.939071</td>\n",
       "      <td>1920.931232</td>\n",
       "      <td>3803.399291</td>\n",
       "      <td>0.069695</td>\n",
       "      <td>-391.126282</td>\n",
       "      <td>84.532150</td>\n",
       "      <td>-7.056905</td>\n",
       "      <td>33.715187</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.142547</td>\n",
       "      <td>-0.036875</td>\n",
       "      <td>-0.463881</td>\n",
       "      <td>-1.210340</td>\n",
       "      <td>-2.041662</td>\n",
       "      <td>-0.094271</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>-0.393657</td>\n",
       "      <td>-0.438716</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chroma_stft      rmse  spectral_centroid  spectral_bandwidth  \\\n",
       "0       0.519951  0.045853        1612.895795         1411.838677   \n",
       "1       0.535472  0.001771        2892.087076         2467.408141   \n",
       "2       0.496666  0.033657        3429.061935         2788.634413   \n",
       "3       0.407549  0.013452        2710.811637         2664.287550   \n",
       "4       0.412697  0.059004        1555.648634         1418.599932   \n",
       "..           ...       ...                ...                 ...   \n",
       "633     0.417148  0.045211        2369.938534         2067.716183   \n",
       "634     0.480541  0.046763        2179.220385         2173.195343   \n",
       "635     0.451153  0.040309        1640.506731         1916.351137   \n",
       "636     0.507765  0.047907        2289.873618         2244.929191   \n",
       "637     0.546504  0.030731        1756.939071         1920.931232   \n",
       "\n",
       "         rolloff  zero_crossing_rate       mfcc1       mfcc2      mfcc3  \\\n",
       "0    2907.580566            0.107019 -376.876007  111.017372 -31.904013   \n",
       "1    5072.664388            0.148584 -519.158447   60.781284 -13.722886   \n",
       "2    6886.288452            0.225315 -282.297913   48.581680 -15.522366   \n",
       "3    5778.474935            0.142076 -346.857300   75.765617  -7.648193   \n",
       "4    2870.737092            0.133998 -340.588013  104.156700 -32.228443   \n",
       "..           ...                 ...         ...         ...        ...   \n",
       "633  4717.735662            0.154040 -282.171326   88.513092 -18.037218   \n",
       "634  4751.847634            0.116623 -359.640625   75.772011   7.082318   \n",
       "635  3635.990574            0.058771 -392.291321   83.491142  12.452518   \n",
       "636  5017.055377            0.127125 -360.749054   82.124313   4.179862   \n",
       "637  3803.399291            0.069695 -391.126282   84.532150  -7.056905   \n",
       "\n",
       "         mfcc4  ...    mfcc32    mfcc33    mfcc34    mfcc35    mfcc36  \\\n",
       "0     6.622254  ... -2.276272 -0.625641 -1.608061 -1.412680 -0.594154   \n",
       "1    52.145428  ...  1.927568 -2.116628  1.253289 -2.312178  1.540753   \n",
       "2    12.710722  ...  2.145280 -2.767728  0.227271 -2.796792 -0.805099   \n",
       "3    11.362121  ...  1.614948 -1.242405 -1.523256 -4.805856 -1.141960   \n",
       "4   -13.615362  ... -0.151529 -1.332800 -0.106066  0.582513 -0.861203   \n",
       "..         ...  ...       ...       ...       ...       ...       ...   \n",
       "633  37.392307  ... -4.575409  0.186341  2.064215  0.425656 -1.561547   \n",
       "634  -0.163865  ... -2.771891 -1.599745 -1.263624  0.775504  2.339190   \n",
       "635  31.852299  ... -1.041149 -0.279625  0.884969 -0.188822 -0.359877   \n",
       "636   1.507247  ... -2.998783 -1.678998 -0.865947 -0.499135  1.030186   \n",
       "637  33.715187  ... -1.142547 -0.036875 -0.463881 -1.210340 -2.041662   \n",
       "\n",
       "       mfcc37    mfcc38    mfcc39    mfcc40      label  \n",
       "0   -2.270374 -1.230999 -1.667140 -0.667805  not_covid  \n",
       "1   -3.853856  1.536122 -3.761888  0.968226  not_covid  \n",
       "2   -2.301651  0.147189 -1.996069  2.062976  not_covid  \n",
       "3   -2.236271 -2.583130 -5.340420 -2.442520  not_covid  \n",
       "4    0.320628  1.574154  0.413459  0.444616      covid  \n",
       "..        ...       ...       ...       ...        ...  \n",
       "633 -0.249007 -1.009573 -2.299492 -1.826561  not_covid  \n",
       "634  1.845072  2.218437  0.752891 -1.126326  not_covid  \n",
       "635 -0.033061  0.041764 -0.197566 -0.147689  not_covid  \n",
       "636  1.320255  1.051911  0.523360 -0.475488  not_covid  \n",
       "637 -0.094271  0.005632 -0.393657 -0.438716  not_covid  \n",
       "\n",
       "[638 rows x 47 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"filename\"], axis=1, inplace=True)\n",
    "df\n",
    "#df[df['label']=='not_covid'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6dc8b2",
   "metadata": {},
   "source": [
    "#loading the dataset we created \n",
    "\n",
    "#remove filename column \n",
    "df.drop([\"filename\"], axis=1, inplace=True)\n",
    "\n",
    "df[df['label']=='not_covid'].count()#188\n",
    "df[df['label']=='covid'].count()#450\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ffe2c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc32</th>\n",
       "      <th>mfcc33</th>\n",
       "      <th>mfcc34</th>\n",
       "      <th>mfcc35</th>\n",
       "      <th>mfcc36</th>\n",
       "      <th>mfcc37</th>\n",
       "      <th>mfcc38</th>\n",
       "      <th>mfcc39</th>\n",
       "      <th>mfcc40</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.519951</td>\n",
       "      <td>0.045853</td>\n",
       "      <td>1612.895795</td>\n",
       "      <td>1411.838677</td>\n",
       "      <td>2907.580566</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>-376.876007</td>\n",
       "      <td>111.017372</td>\n",
       "      <td>-31.904013</td>\n",
       "      <td>6.622254</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.276272</td>\n",
       "      <td>-0.625641</td>\n",
       "      <td>-1.608061</td>\n",
       "      <td>-1.412680</td>\n",
       "      <td>-0.594154</td>\n",
       "      <td>-2.270374</td>\n",
       "      <td>-1.230999</td>\n",
       "      <td>-1.667140</td>\n",
       "      <td>-0.667805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535472</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>2892.087076</td>\n",
       "      <td>2467.408141</td>\n",
       "      <td>5072.664388</td>\n",
       "      <td>0.148584</td>\n",
       "      <td>-519.158447</td>\n",
       "      <td>60.781284</td>\n",
       "      <td>-13.722886</td>\n",
       "      <td>52.145428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.927568</td>\n",
       "      <td>-2.116628</td>\n",
       "      <td>1.253289</td>\n",
       "      <td>-2.312178</td>\n",
       "      <td>1.540753</td>\n",
       "      <td>-3.853856</td>\n",
       "      <td>1.536122</td>\n",
       "      <td>-3.761888</td>\n",
       "      <td>0.968226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.496666</td>\n",
       "      <td>0.033657</td>\n",
       "      <td>3429.061935</td>\n",
       "      <td>2788.634413</td>\n",
       "      <td>6886.288452</td>\n",
       "      <td>0.225315</td>\n",
       "      <td>-282.297913</td>\n",
       "      <td>48.581680</td>\n",
       "      <td>-15.522366</td>\n",
       "      <td>12.710722</td>\n",
       "      <td>...</td>\n",
       "      <td>2.145280</td>\n",
       "      <td>-2.767728</td>\n",
       "      <td>0.227271</td>\n",
       "      <td>-2.796792</td>\n",
       "      <td>-0.805099</td>\n",
       "      <td>-2.301651</td>\n",
       "      <td>0.147189</td>\n",
       "      <td>-1.996069</td>\n",
       "      <td>2.062976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407549</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>2710.811637</td>\n",
       "      <td>2664.287550</td>\n",
       "      <td>5778.474935</td>\n",
       "      <td>0.142076</td>\n",
       "      <td>-346.857300</td>\n",
       "      <td>75.765617</td>\n",
       "      <td>-7.648193</td>\n",
       "      <td>11.362121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.614948</td>\n",
       "      <td>-1.242405</td>\n",
       "      <td>-1.523256</td>\n",
       "      <td>-4.805856</td>\n",
       "      <td>-1.141960</td>\n",
       "      <td>-2.236271</td>\n",
       "      <td>-2.583130</td>\n",
       "      <td>-5.340420</td>\n",
       "      <td>-2.442520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.412697</td>\n",
       "      <td>0.059004</td>\n",
       "      <td>1555.648634</td>\n",
       "      <td>1418.599932</td>\n",
       "      <td>2870.737092</td>\n",
       "      <td>0.133998</td>\n",
       "      <td>-340.588013</td>\n",
       "      <td>104.156700</td>\n",
       "      <td>-32.228443</td>\n",
       "      <td>-13.615362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151529</td>\n",
       "      <td>-1.332800</td>\n",
       "      <td>-0.106066</td>\n",
       "      <td>0.582513</td>\n",
       "      <td>-0.861203</td>\n",
       "      <td>0.320628</td>\n",
       "      <td>1.574154</td>\n",
       "      <td>0.413459</td>\n",
       "      <td>0.444616</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.417148</td>\n",
       "      <td>0.045211</td>\n",
       "      <td>2369.938534</td>\n",
       "      <td>2067.716183</td>\n",
       "      <td>4717.735662</td>\n",
       "      <td>0.154040</td>\n",
       "      <td>-282.171326</td>\n",
       "      <td>88.513092</td>\n",
       "      <td>-18.037218</td>\n",
       "      <td>37.392307</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.575409</td>\n",
       "      <td>0.186341</td>\n",
       "      <td>2.064215</td>\n",
       "      <td>0.425656</td>\n",
       "      <td>-1.561547</td>\n",
       "      <td>-0.249007</td>\n",
       "      <td>-1.009573</td>\n",
       "      <td>-2.299492</td>\n",
       "      <td>-1.826561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.480541</td>\n",
       "      <td>0.046763</td>\n",
       "      <td>2179.220385</td>\n",
       "      <td>2173.195343</td>\n",
       "      <td>4751.847634</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>-359.640625</td>\n",
       "      <td>75.772011</td>\n",
       "      <td>7.082318</td>\n",
       "      <td>-0.163865</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.771891</td>\n",
       "      <td>-1.599745</td>\n",
       "      <td>-1.263624</td>\n",
       "      <td>0.775504</td>\n",
       "      <td>2.339190</td>\n",
       "      <td>1.845072</td>\n",
       "      <td>2.218437</td>\n",
       "      <td>0.752891</td>\n",
       "      <td>-1.126326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.451153</td>\n",
       "      <td>0.040309</td>\n",
       "      <td>1640.506731</td>\n",
       "      <td>1916.351137</td>\n",
       "      <td>3635.990574</td>\n",
       "      <td>0.058771</td>\n",
       "      <td>-392.291321</td>\n",
       "      <td>83.491142</td>\n",
       "      <td>12.452518</td>\n",
       "      <td>31.852299</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.041149</td>\n",
       "      <td>-0.279625</td>\n",
       "      <td>0.884969</td>\n",
       "      <td>-0.188822</td>\n",
       "      <td>-0.359877</td>\n",
       "      <td>-0.033061</td>\n",
       "      <td>0.041764</td>\n",
       "      <td>-0.197566</td>\n",
       "      <td>-0.147689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.507765</td>\n",
       "      <td>0.047907</td>\n",
       "      <td>2289.873618</td>\n",
       "      <td>2244.929191</td>\n",
       "      <td>5017.055377</td>\n",
       "      <td>0.127125</td>\n",
       "      <td>-360.749054</td>\n",
       "      <td>82.124313</td>\n",
       "      <td>4.179862</td>\n",
       "      <td>1.507247</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.998783</td>\n",
       "      <td>-1.678998</td>\n",
       "      <td>-0.865947</td>\n",
       "      <td>-0.499135</td>\n",
       "      <td>1.030186</td>\n",
       "      <td>1.320255</td>\n",
       "      <td>1.051911</td>\n",
       "      <td>0.523360</td>\n",
       "      <td>-0.475488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0.546504</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>1756.939071</td>\n",
       "      <td>1920.931232</td>\n",
       "      <td>3803.399291</td>\n",
       "      <td>0.069695</td>\n",
       "      <td>-391.126282</td>\n",
       "      <td>84.532150</td>\n",
       "      <td>-7.056905</td>\n",
       "      <td>33.715187</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.142547</td>\n",
       "      <td>-0.036875</td>\n",
       "      <td>-0.463881</td>\n",
       "      <td>-1.210340</td>\n",
       "      <td>-2.041662</td>\n",
       "      <td>-0.094271</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>-0.393657</td>\n",
       "      <td>-0.438716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chroma_stft      rmse  spectral_centroid  spectral_bandwidth  \\\n",
       "0       0.519951  0.045853        1612.895795         1411.838677   \n",
       "1       0.535472  0.001771        2892.087076         2467.408141   \n",
       "2       0.496666  0.033657        3429.061935         2788.634413   \n",
       "3       0.407549  0.013452        2710.811637         2664.287550   \n",
       "4       0.412697  0.059004        1555.648634         1418.599932   \n",
       "..           ...       ...                ...                 ...   \n",
       "633     0.417148  0.045211        2369.938534         2067.716183   \n",
       "634     0.480541  0.046763        2179.220385         2173.195343   \n",
       "635     0.451153  0.040309        1640.506731         1916.351137   \n",
       "636     0.507765  0.047907        2289.873618         2244.929191   \n",
       "637     0.546504  0.030731        1756.939071         1920.931232   \n",
       "\n",
       "         rolloff  zero_crossing_rate       mfcc1       mfcc2      mfcc3  \\\n",
       "0    2907.580566            0.107019 -376.876007  111.017372 -31.904013   \n",
       "1    5072.664388            0.148584 -519.158447   60.781284 -13.722886   \n",
       "2    6886.288452            0.225315 -282.297913   48.581680 -15.522366   \n",
       "3    5778.474935            0.142076 -346.857300   75.765617  -7.648193   \n",
       "4    2870.737092            0.133998 -340.588013  104.156700 -32.228443   \n",
       "..           ...                 ...         ...         ...        ...   \n",
       "633  4717.735662            0.154040 -282.171326   88.513092 -18.037218   \n",
       "634  4751.847634            0.116623 -359.640625   75.772011   7.082318   \n",
       "635  3635.990574            0.058771 -392.291321   83.491142  12.452518   \n",
       "636  5017.055377            0.127125 -360.749054   82.124313   4.179862   \n",
       "637  3803.399291            0.069695 -391.126282   84.532150  -7.056905   \n",
       "\n",
       "         mfcc4  ...    mfcc32    mfcc33    mfcc34    mfcc35    mfcc36  \\\n",
       "0     6.622254  ... -2.276272 -0.625641 -1.608061 -1.412680 -0.594154   \n",
       "1    52.145428  ...  1.927568 -2.116628  1.253289 -2.312178  1.540753   \n",
       "2    12.710722  ...  2.145280 -2.767728  0.227271 -2.796792 -0.805099   \n",
       "3    11.362121  ...  1.614948 -1.242405 -1.523256 -4.805856 -1.141960   \n",
       "4   -13.615362  ... -0.151529 -1.332800 -0.106066  0.582513 -0.861203   \n",
       "..         ...  ...       ...       ...       ...       ...       ...   \n",
       "633  37.392307  ... -4.575409  0.186341  2.064215  0.425656 -1.561547   \n",
       "634  -0.163865  ... -2.771891 -1.599745 -1.263624  0.775504  2.339190   \n",
       "635  31.852299  ... -1.041149 -0.279625  0.884969 -0.188822 -0.359877   \n",
       "636   1.507247  ... -2.998783 -1.678998 -0.865947 -0.499135  1.030186   \n",
       "637  33.715187  ... -1.142547 -0.036875 -0.463881 -1.210340 -2.041662   \n",
       "\n",
       "       mfcc37    mfcc38    mfcc39    mfcc40  label  \n",
       "0   -2.270374 -1.230999 -1.667140 -0.667805      0  \n",
       "1   -3.853856  1.536122 -3.761888  0.968226      0  \n",
       "2   -2.301651  0.147189 -1.996069  2.062976      0  \n",
       "3   -2.236271 -2.583130 -5.340420 -2.442520      0  \n",
       "4    0.320628  1.574154  0.413459  0.444616      1  \n",
       "..        ...       ...       ...       ...    ...  \n",
       "633 -0.249007 -1.009573 -2.299492 -1.826561      0  \n",
       "634  1.845072  2.218437  0.752891 -1.126326      0  \n",
       "635 -0.033061  0.041764 -0.197566 -0.147689      0  \n",
       "636  1.320255  1.051911  0.523360 -0.475488      0  \n",
       "637 -0.094271  0.005632 -0.393657 -0.438716      0  \n",
       "\n",
       "[638 rows x 47 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapping for the results\n",
    "#df.label.replace({\"positive\":int(1)},inplace=True)\n",
    "#df.label.replace({\"negative\":int(0)},inplace=True)\n",
    "#df\n",
    "\n",
    "map_dict = {\"covid\":1, \"not_covid\":0}\n",
    "\n",
    "#mapping the values of the dict \n",
    "df['label'] = df['label'].map(map_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e97d08d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc32</th>\n",
       "      <th>mfcc33</th>\n",
       "      <th>mfcc34</th>\n",
       "      <th>mfcc35</th>\n",
       "      <th>mfcc36</th>\n",
       "      <th>mfcc37</th>\n",
       "      <th>mfcc38</th>\n",
       "      <th>mfcc39</th>\n",
       "      <th>mfcc40</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.352629</td>\n",
       "      <td>0.025174</td>\n",
       "      <td>1248.970192</td>\n",
       "      <td>1346.012498</td>\n",
       "      <td>2466.298574</td>\n",
       "      <td>0.061501</td>\n",
       "      <td>-335.500397</td>\n",
       "      <td>130.116379</td>\n",
       "      <td>-22.011730</td>\n",
       "      <td>24.498240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365342</td>\n",
       "      <td>2.715003</td>\n",
       "      <td>0.880463</td>\n",
       "      <td>3.252186</td>\n",
       "      <td>2.388905</td>\n",
       "      <td>-0.517920</td>\n",
       "      <td>2.105383</td>\n",
       "      <td>0.787770</td>\n",
       "      <td>1.949712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.317862</td>\n",
       "      <td>0.048421</td>\n",
       "      <td>1689.943148</td>\n",
       "      <td>1302.269290</td>\n",
       "      <td>3204.110718</td>\n",
       "      <td>0.102417</td>\n",
       "      <td>-289.232544</td>\n",
       "      <td>152.858658</td>\n",
       "      <td>-84.176132</td>\n",
       "      <td>43.611568</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.229112</td>\n",
       "      <td>-1.413199</td>\n",
       "      <td>-3.264344</td>\n",
       "      <td>-2.743153</td>\n",
       "      <td>-1.694523</td>\n",
       "      <td>-3.286030</td>\n",
       "      <td>-2.295405</td>\n",
       "      <td>-3.416353</td>\n",
       "      <td>-1.705313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.551745</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>2322.953790</td>\n",
       "      <td>2066.219477</td>\n",
       "      <td>4694.138590</td>\n",
       "      <td>0.192912</td>\n",
       "      <td>-444.070374</td>\n",
       "      <td>91.228889</td>\n",
       "      <td>-21.199741</td>\n",
       "      <td>26.116728</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.674739</td>\n",
       "      <td>-1.509492</td>\n",
       "      <td>-1.061414</td>\n",
       "      <td>-0.503645</td>\n",
       "      <td>-0.396995</td>\n",
       "      <td>2.032535</td>\n",
       "      <td>1.726185</td>\n",
       "      <td>0.161908</td>\n",
       "      <td>0.691548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.335650</td>\n",
       "      <td>0.131941</td>\n",
       "      <td>1316.384645</td>\n",
       "      <td>904.672370</td>\n",
       "      <td>2289.647420</td>\n",
       "      <td>0.094711</td>\n",
       "      <td>-210.104004</td>\n",
       "      <td>166.321671</td>\n",
       "      <td>-77.953316</td>\n",
       "      <td>-9.101565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.248921</td>\n",
       "      <td>-1.397628</td>\n",
       "      <td>0.090844</td>\n",
       "      <td>-2.206384</td>\n",
       "      <td>-3.436520</td>\n",
       "      <td>-0.231270</td>\n",
       "      <td>-2.853828</td>\n",
       "      <td>-4.302076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.398966</td>\n",
       "      <td>0.006810</td>\n",
       "      <td>1797.366779</td>\n",
       "      <td>1843.769746</td>\n",
       "      <td>4041.612228</td>\n",
       "      <td>0.100843</td>\n",
       "      <td>-439.907562</td>\n",
       "      <td>113.110565</td>\n",
       "      <td>-11.171643</td>\n",
       "      <td>30.277735</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.380815</td>\n",
       "      <td>4.863899</td>\n",
       "      <td>-1.398247</td>\n",
       "      <td>2.368197</td>\n",
       "      <td>0.038018</td>\n",
       "      <td>-0.307650</td>\n",
       "      <td>0.615264</td>\n",
       "      <td>-0.133031</td>\n",
       "      <td>1.985461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.556056</td>\n",
       "      <td>0.056683</td>\n",
       "      <td>1715.094000</td>\n",
       "      <td>1499.819557</td>\n",
       "      <td>3237.706502</td>\n",
       "      <td>0.127496</td>\n",
       "      <td>-336.530670</td>\n",
       "      <td>104.179688</td>\n",
       "      <td>-26.436058</td>\n",
       "      <td>20.859140</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.669253</td>\n",
       "      <td>-3.395215</td>\n",
       "      <td>-2.797870</td>\n",
       "      <td>-1.262121</td>\n",
       "      <td>-1.300293</td>\n",
       "      <td>-2.150868</td>\n",
       "      <td>-0.334707</td>\n",
       "      <td>-0.418320</td>\n",
       "      <td>-0.021768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.411479</td>\n",
       "      <td>0.066689</td>\n",
       "      <td>1596.334605</td>\n",
       "      <td>1350.273478</td>\n",
       "      <td>2913.046370</td>\n",
       "      <td>0.104913</td>\n",
       "      <td>-240.397873</td>\n",
       "      <td>118.980301</td>\n",
       "      <td>-64.273132</td>\n",
       "      <td>22.916378</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.579738</td>\n",
       "      <td>2.384022</td>\n",
       "      <td>-3.756382</td>\n",
       "      <td>1.715501</td>\n",
       "      <td>-1.417742</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>-1.352304</td>\n",
       "      <td>-1.253641</td>\n",
       "      <td>1.363693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.414679</td>\n",
       "      <td>0.063298</td>\n",
       "      <td>2751.067894</td>\n",
       "      <td>2241.370857</td>\n",
       "      <td>5473.256517</td>\n",
       "      <td>0.230370</td>\n",
       "      <td>-254.415253</td>\n",
       "      <td>78.819206</td>\n",
       "      <td>-27.291359</td>\n",
       "      <td>7.474739</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.654064</td>\n",
       "      <td>-0.977543</td>\n",
       "      <td>-3.012755</td>\n",
       "      <td>1.010672</td>\n",
       "      <td>-1.450121</td>\n",
       "      <td>3.227950</td>\n",
       "      <td>-0.651933</td>\n",
       "      <td>-0.835360</td>\n",
       "      <td>0.132376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.408098</td>\n",
       "      <td>0.068758</td>\n",
       "      <td>3039.896816</td>\n",
       "      <td>2367.403309</td>\n",
       "      <td>5634.770711</td>\n",
       "      <td>0.202616</td>\n",
       "      <td>-191.739151</td>\n",
       "      <td>54.799397</td>\n",
       "      <td>-25.771214</td>\n",
       "      <td>18.545555</td>\n",
       "      <td>...</td>\n",
       "      <td>1.962469</td>\n",
       "      <td>-0.460964</td>\n",
       "      <td>-0.679246</td>\n",
       "      <td>-1.431800</td>\n",
       "      <td>-1.565870</td>\n",
       "      <td>-1.671580</td>\n",
       "      <td>-1.115053</td>\n",
       "      <td>-2.079583</td>\n",
       "      <td>-0.378173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.425251</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>2885.344916</td>\n",
       "      <td>2777.170836</td>\n",
       "      <td>6010.754395</td>\n",
       "      <td>0.156440</td>\n",
       "      <td>-457.538788</td>\n",
       "      <td>64.385582</td>\n",
       "      <td>4.163181</td>\n",
       "      <td>5.005247</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.211666</td>\n",
       "      <td>-0.748252</td>\n",
       "      <td>1.559851</td>\n",
       "      <td>1.657498</td>\n",
       "      <td>1.707591</td>\n",
       "      <td>0.913274</td>\n",
       "      <td>-0.894709</td>\n",
       "      <td>-1.490525</td>\n",
       "      <td>-1.549160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chroma_stft      rmse  spectral_centroid  spectral_bandwidth  \\\n",
       "320     0.352629  0.025174        1248.970192         1346.012498   \n",
       "53      0.317862  0.048421        1689.943148         1302.269290   \n",
       "567     0.551745  0.013618        2322.953790         2066.219477   \n",
       "128     0.335650  0.131941        1316.384645          904.672370   \n",
       "200     0.398966  0.006810        1797.366779         1843.769746   \n",
       "..           ...       ...                ...                 ...   \n",
       "348     0.556056  0.056683        1715.094000         1499.819557   \n",
       "303     0.411479  0.066689        1596.334605         1350.273478   \n",
       "397     0.414679  0.063298        2751.067894         2241.370857   \n",
       "87      0.408098  0.068758        3039.896816         2367.403309   \n",
       "110     0.425251  0.010333        2885.344916         2777.170836   \n",
       "\n",
       "         rolloff  zero_crossing_rate       mfcc1       mfcc2      mfcc3  \\\n",
       "320  2466.298574            0.061501 -335.500397  130.116379 -22.011730   \n",
       "53   3204.110718            0.102417 -289.232544  152.858658 -84.176132   \n",
       "567  4694.138590            0.192912 -444.070374   91.228889 -21.199741   \n",
       "128  2289.647420            0.094711 -210.104004  166.321671 -77.953316   \n",
       "200  4041.612228            0.100843 -439.907562  113.110565 -11.171643   \n",
       "..           ...                 ...         ...         ...        ...   \n",
       "348  3237.706502            0.127496 -336.530670  104.179688 -26.436058   \n",
       "303  2913.046370            0.104913 -240.397873  118.980301 -64.273132   \n",
       "397  5473.256517            0.230370 -254.415253   78.819206 -27.291359   \n",
       "87   5634.770711            0.202616 -191.739151   54.799397 -25.771214   \n",
       "110  6010.754395            0.156440 -457.538788   64.385582   4.163181   \n",
       "\n",
       "         mfcc4  ...    mfcc32    mfcc33    mfcc34    mfcc35    mfcc36  \\\n",
       "320  24.498240  ...  0.365342  2.715003  0.880463  3.252186  2.388905   \n",
       "53   43.611568  ... -2.229112 -1.413199 -3.264344 -2.743153 -1.694523   \n",
       "567  26.116728  ... -3.674739 -1.509492 -1.061414 -0.503645 -0.396995   \n",
       "128  -9.101565  ...  0.004326  0.248921 -1.397628  0.090844 -2.206384   \n",
       "200  30.277735  ... -1.380815  4.863899 -1.398247  2.368197  0.038018   \n",
       "..         ...  ...       ...       ...       ...       ...       ...   \n",
       "348  20.859140  ... -3.669253 -3.395215 -2.797870 -1.262121 -1.300293   \n",
       "303  22.916378  ... -4.579738  2.384022 -3.756382  1.715501 -1.417742   \n",
       "397   7.474739  ... -5.654064 -0.977543 -3.012755  1.010672 -1.450121   \n",
       "87   18.545555  ...  1.962469 -0.460964 -0.679246 -1.431800 -1.565870   \n",
       "110   5.005247  ... -1.211666 -0.748252  1.559851  1.657498  1.707591   \n",
       "\n",
       "       mfcc37    mfcc38    mfcc39    mfcc40  label  \n",
       "320 -0.517920  2.105383  0.787770  1.949712      1  \n",
       "53  -3.286030 -2.295405 -3.416353 -1.705313      0  \n",
       "567  2.032535  1.726185  0.161908  0.691548      1  \n",
       "128 -3.436520 -0.231270 -2.853828 -4.302076      0  \n",
       "200 -0.307650  0.615264 -0.133031  1.985461      1  \n",
       "..        ...       ...       ...       ...    ...  \n",
       "348 -2.150868 -0.334707 -0.418320 -0.021768      1  \n",
       "303 -0.079549 -1.352304 -1.253641  1.363693      1  \n",
       "397  3.227950 -0.651933 -0.835360  0.132376      1  \n",
       "87  -1.671580 -1.115053 -2.079583 -0.378173      0  \n",
       "110  0.913274 -0.894709 -1.490525 -1.549160      0  \n",
       "\n",
       "[638 rows x 47 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffling the data set \n",
    "#since all the positives were first and negatives last\n",
    "shuffle_train_df = df.reindex(np.random.permutation(df.index))\n",
    "shuffle_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce65049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-Learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imbalanced-Learn) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imbalanced-Learn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imbalanced-Learn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imbalanced-Learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imbalanced-Learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install imbalanced-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e864d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels\n",
    "y = shuffle_train_df['label'].to_numpy()\n",
    "\n",
    "#rest of data\n",
    "X = (shuffle_train_df.iloc[:, :-1]).to_numpy()\n",
    "y\n",
    "X\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(sampling_strategy='minority')\n",
    "x_sm,y_sm=smote.fit_resample(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbeaf883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the Label Encoder \n",
    "le = LabelEncoder()\n",
    "\n",
    "#fit and transform the encoder \n",
    "y = le.fit_transform(y_sm)\n",
    "\n",
    "\n",
    "#instantiate scaler \n",
    "stsc = StandardScaler().fit(x_sm)\n",
    "\n",
    "#fit transform scaler \n",
    "X=stsc.transform(x_sm)\n",
    "y\n",
    "from imblearn.over_sampling import SMOTE\n",
    "y=np.array(pd.get_dummies(y))\n",
    "y\n",
    "\n",
    "#separating the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6afc0721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 1s 34ms/step - loss: 1.1343 - accuracy: 0.5143 - val_loss: 0.6235 - val_accuracy: 0.6296\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8745 - accuracy: 0.6143 - val_loss: 0.5417 - val_accuracy: 0.7519\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7441 - accuracy: 0.6889 - val_loss: 0.4458 - val_accuracy: 0.8444\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6364 - accuracy: 0.7762 - val_loss: 0.3781 - val_accuracy: 0.8593\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5533 - accuracy: 0.8190 - val_loss: 0.3414 - val_accuracy: 0.8741\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4808 - accuracy: 0.8302 - val_loss: 0.3173 - val_accuracy: 0.8926\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8714 - val_loss: 0.2988 - val_accuracy: 0.9185\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3545 - accuracy: 0.8905 - val_loss: 0.2820 - val_accuracy: 0.9259\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3427 - accuracy: 0.8952 - val_loss: 0.2741 - val_accuracy: 0.9370\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3000 - accuracy: 0.9063 - val_loss: 0.2463 - val_accuracy: 0.9481\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3140 - accuracy: 0.9016 - val_loss: 0.2521 - val_accuracy: 0.9370\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2299 - accuracy: 0.9397 - val_loss: 0.2323 - val_accuracy: 0.9444\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2445 - accuracy: 0.9349 - val_loss: 0.2115 - val_accuracy: 0.9481\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2244 - accuracy: 0.9302 - val_loss: 0.2020 - val_accuracy: 0.9519\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1975 - accuracy: 0.9429 - val_loss: 0.1994 - val_accuracy: 0.9519\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1766 - accuracy: 0.9460 - val_loss: 0.1821 - val_accuracy: 0.9556\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1859 - accuracy: 0.9476 - val_loss: 0.1851 - val_accuracy: 0.9556\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1690 - accuracy: 0.9508 - val_loss: 0.1732 - val_accuracy: 0.9556\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1357 - accuracy: 0.9587 - val_loss: 0.1736 - val_accuracy: 0.9444\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1524 - accuracy: 0.9587 - val_loss: 0.1600 - val_accuracy: 0.9444\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1367 - accuracy: 0.9540 - val_loss: 0.1453 - val_accuracy: 0.9593\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1444 - accuracy: 0.9619 - val_loss: 0.1477 - val_accuracy: 0.9630\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1462 - accuracy: 0.9635 - val_loss: 0.1425 - val_accuracy: 0.9556\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0978 - accuracy: 0.9810 - val_loss: 0.1405 - val_accuracy: 0.9630\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1307 - accuracy: 0.9635 - val_loss: 0.1354 - val_accuracy: 0.9667\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1246 - accuracy: 0.9651 - val_loss: 0.1322 - val_accuracy: 0.9667\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0900 - accuracy: 0.9762 - val_loss: 0.1245 - val_accuracy: 0.9704\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1003 - accuracy: 0.9746 - val_loss: 0.1256 - val_accuracy: 0.9667\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0863 - accuracy: 0.9746 - val_loss: 0.1232 - val_accuracy: 0.9741\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0764 - accuracy: 0.9762 - val_loss: 0.1204 - val_accuracy: 0.9741\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0602 - accuracy: 0.9857 - val_loss: 0.1235 - val_accuracy: 0.9778\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0701 - accuracy: 0.9857 - val_loss: 0.1259 - val_accuracy: 0.9778\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0627 - accuracy: 0.9794 - val_loss: 0.1268 - val_accuracy: 0.9778\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0729 - accuracy: 0.9810 - val_loss: 0.1282 - val_accuracy: 0.9778\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0875 - accuracy: 0.9714 - val_loss: 0.1338 - val_accuracy: 0.9778\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0581 - accuracy: 0.9857 - val_loss: 0.1394 - val_accuracy: 0.9778\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0752 - accuracy: 0.9778 - val_loss: 0.1426 - val_accuracy: 0.9741\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.9873 - val_loss: 0.1444 - val_accuracy: 0.9741\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0384 - accuracy: 0.9905 - val_loss: 0.1371 - val_accuracy: 0.9667\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.1392 - val_accuracy: 0.9704\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0481 - accuracy: 0.9905 - val_loss: 0.1496 - val_accuracy: 0.9704\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.9905 - val_loss: 0.1235 - val_accuracy: 0.9778\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9921 - val_loss: 0.1208 - val_accuracy: 0.9778\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0641 - accuracy: 0.9905 - val_loss: 0.1220 - val_accuracy: 0.9778\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 0.1287 - val_accuracy: 0.9741\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.1344 - val_accuracy: 0.9741\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9889 - val_loss: 0.1382 - val_accuracy: 0.9741\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9937 - val_loss: 0.1408 - val_accuracy: 0.9741\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9889 - val_loss: 0.1334 - val_accuracy: 0.9741\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9857 - val_loss: 0.1391 - val_accuracy: 0.9741\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0472 - accuracy: 0.9952 - val_loss: 0.1481 - val_accuracy: 0.9741\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9857 - val_loss: 0.1510 - val_accuracy: 0.9741\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.1547 - val_accuracy: 0.9741\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.1564 - val_accuracy: 0.9741\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.1617 - val_accuracy: 0.9741\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9921 - val_loss: 0.1607 - val_accuracy: 0.9741\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0208 - accuracy: 0.9968 - val_loss: 0.1510 - val_accuracy: 0.9778\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9873 - val_loss: 0.1588 - val_accuracy: 0.9778\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9968 - val_loss: 0.1752 - val_accuracy: 0.9741\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9952 - val_loss: 0.1785 - val_accuracy: 0.9741\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0432 - accuracy: 0.9889 - val_loss: 0.1744 - val_accuracy: 0.9741\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9873 - val_loss: 0.1603 - val_accuracy: 0.9741\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 0.1544 - val_accuracy: 0.9741\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9968 - val_loss: 0.1551 - val_accuracy: 0.9815\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0213 - accuracy: 0.9921 - val_loss: 0.1720 - val_accuracy: 0.9741\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 0.9984 - val_loss: 0.1827 - val_accuracy: 0.9741\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 0.1645 - val_accuracy: 0.9778\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0188 - accuracy: 0.9968 - val_loss: 0.1566 - val_accuracy: 0.9852\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9937 - val_loss: 0.1590 - val_accuracy: 0.9852\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.1565 - val_accuracy: 0.9852\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.9984 - val_loss: 0.1615 - val_accuracy: 0.9852\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 0.1639 - val_accuracy: 0.9815\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0336 - accuracy: 0.9952 - val_loss: 0.1664 - val_accuracy: 0.9778\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.1641 - val_accuracy: 0.9778\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9968 - val_loss: 0.1653 - val_accuracy: 0.9778\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.1542 - val_accuracy: 0.9815\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.1557 - val_accuracy: 0.9852\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0115 - accuracy: 0.9984 - val_loss: 0.1589 - val_accuracy: 0.9815\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.1677 - val_accuracy: 0.9815\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9778\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.1804 - val_accuracy: 0.9778\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.1788 - val_accuracy: 0.9815\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9937 - val_loss: 0.1870 - val_accuracy: 0.9815\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.1941 - val_accuracy: 0.9778\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.1868 - val_accuracy: 0.9815\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.1760 - val_accuracy: 0.9852\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.1793 - val_accuracy: 0.9852\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.1826 - val_accuracy: 0.9852\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.1863 - val_accuracy: 0.9815\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9968 - val_loss: 0.1969 - val_accuracy: 0.9815\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.2047 - val_accuracy: 0.9815\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9778\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.2089 - val_accuracy: 0.9778\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0457 - accuracy: 0.9968 - val_loss: 0.2174 - val_accuracy: 0.9778\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9852\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9852\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9852\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.1994 - val_accuracy: 0.9852\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1956 - val_accuracy: 0.9889\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.1891 - val_accuracy: 0.9889\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.1910 - val_accuracy: 0.9815\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.2000 - val_accuracy: 0.9815\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9815\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9815\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9815\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.2182 - val_accuracy: 0.9778\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.2120 - val_accuracy: 0.9815\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9815\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.2220 - val_accuracy: 0.9778\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - accuracy: 0.9984 - val_loss: 0.2512 - val_accuracy: 0.9815\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.2575 - val_accuracy: 0.9815\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.2507 - val_accuracy: 0.9815\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9815\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.2528 - val_accuracy: 0.9815\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9815\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 0.9937 - val_loss: 0.2395 - val_accuracy: 0.9852\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.2315 - val_accuracy: 0.9852\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 0.9968 - val_loss: 0.2358 - val_accuracy: 0.9815\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 0.9984 - val_loss: 0.2235 - val_accuracy: 0.9741\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9741\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.2238 - val_accuracy: 0.9778\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.2159 - val_accuracy: 0.9778\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9952 - val_loss: 0.2193 - val_accuracy: 0.9778\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.2216 - val_accuracy: 0.9778\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.2278 - val_accuracy: 0.9815\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.2164 - val_accuracy: 0.9778\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.2167 - val_accuracy: 0.9778\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.2233 - val_accuracy: 0.9778\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.2443 - val_accuracy: 0.9741\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.2652 - val_accuracy: 0.9741\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9741\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.2554 - val_accuracy: 0.9741\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9889 - val_loss: 0.2491 - val_accuracy: 0.9741\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.5755e-04 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9778\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.2488 - val_accuracy: 0.9815\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.2415 - val_accuracy: 0.9815\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.2542 - val_accuracy: 0.9815\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9815\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.2512 - val_accuracy: 0.9815\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.2294 - val_accuracy: 0.9778\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.9024e-04 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9778\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.2260 - val_accuracy: 0.9741\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9937 - val_loss: 0.2323 - val_accuracy: 0.9778\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.2331 - val_accuracy: 0.9778\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 0.9984 - val_loss: 0.2402 - val_accuracy: 0.9778\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9778\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9778\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.2329 - val_accuracy: 0.9778\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9778\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.2387 - val_accuracy: 0.9778\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 0.2447 - val_accuracy: 0.9778\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9778\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.2353 - val_accuracy: 0.9852\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.2377 - val_accuracy: 0.9852\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.4044e-04 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9815\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9778\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9778\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.8424e-04 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9778\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9778\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 0.9968 - val_loss: 0.2676 - val_accuracy: 0.9778\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9968 - val_loss: 0.2411 - val_accuracy: 0.9778\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9815\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 0.9968 - val_loss: 0.2353 - val_accuracy: 0.9778\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.2310 - val_accuracy: 0.9815\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9778\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9778\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 0.9952 - val_loss: 0.2345 - val_accuracy: 0.9778\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9778\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0179 - accuracy: 0.9984 - val_loss: 0.2319 - val_accuracy: 0.9815\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.9968 - val_loss: 0.2388 - val_accuracy: 0.9815\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9952 - val_loss: 0.2433 - val_accuracy: 0.9778\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9778\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.2428 - val_accuracy: 0.9778\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9778\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.2395 - val_accuracy: 0.9778\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.2445 - val_accuracy: 0.9778\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.5784e-04 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9778\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.2551 - val_accuracy: 0.9778\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.7791e-04 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9778\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.2659 - val_accuracy: 0.9778\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.8449e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9778\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9984 - val_loss: 0.2690 - val_accuracy: 0.9778\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9778\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9778\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.2792 - val_accuracy: 0.9778\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 0.9984 - val_loss: 0.2868 - val_accuracy: 0.9778\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9778\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.0864e-04 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9778\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9778\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 0.2835 - val_accuracy: 0.9778\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9778\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 0.9968 - val_loss: 0.2696 - val_accuracy: 0.9778\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.9952 - val_loss: 0.2642 - val_accuracy: 0.9778\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9778\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9778\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.6379e-04 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9778\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 0.9984 - val_loss: 0.2654 - val_accuracy: 0.9778\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0395 - accuracy: 0.9937 - val_loss: 0.3466 - val_accuracy: 0.9815\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0129 - accuracy: 0.9937 - val_loss: 0.3701 - val_accuracy: 0.9815\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.3417 - val_accuracy: 0.9852\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9852\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.3085 - val_accuracy: 0.9815\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.2962 - val_accuracy: 0.9815\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9815\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.3059 - val_accuracy: 0.9815\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.9815\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9815\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.5892e-04 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9815\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 0.9968 - val_loss: 0.3338 - val_accuracy: 0.9815\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9815\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.3308 - val_accuracy: 0.9815\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9815\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 0.9968 - val_loss: 0.3175 - val_accuracy: 0.9852\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9852\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.3096 - val_accuracy: 0.9852\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.9984 - val_loss: 0.2941 - val_accuracy: 0.9852\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.2939 - val_accuracy: 0.9852\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.2954 - val_accuracy: 0.9852\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.2946 - val_accuracy: 0.9852\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.3004 - val_accuracy: 0.9852\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4.4042e-04 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.9852\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.9852\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.3113 - val_accuracy: 0.9852\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.9138e-04 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9852\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.9852\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.9527e-04 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9889\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.2525e-04 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9889\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.3107 - val_accuracy: 0.9852\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.3099 - val_accuracy: 0.9852\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.3108 - val_accuracy: 0.9852\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.3080 - val_accuracy: 0.9852\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.3025 - val_accuracy: 0.9852\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.3054 - val_accuracy: 0.9852\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9852\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5.3203e-04 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9815\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.3147 - val_accuracy: 0.9852\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.0021e-04 - accuracy: 1.0000 - val_loss: 0.3208 - val_accuracy: 0.9852\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.9984 - val_loss: 0.3266 - val_accuracy: 0.9852\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.7547e-04 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9852\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9852\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.5602e-04 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.9852\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9852\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - accuracy: 0.9984 - val_loss: 0.3370 - val_accuracy: 0.9889\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9889\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9852\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.3418 - val_accuracy: 0.9852\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3328 - val_accuracy: 0.9852\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4.4325e-04 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9815\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.4731e-04 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.9815\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9815\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.2824e-04 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9852\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1440e-04 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9852\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 9.6985e-05 - accuracy: 1.0000 - val_loss: 0.3269 - val_accuracy: 0.9852\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9852\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 9.3261e-04 - accuracy: 1.0000 - val_loss: 0.3287 - val_accuracy: 0.9815\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9815\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.7606e-04 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9815\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.8488e-04 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9815\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.3179 - val_accuracy: 0.9889\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.5732e-04 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9889\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.3220 - val_accuracy: 0.9852\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.9984 - val_loss: 0.3333 - val_accuracy: 0.9815\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.0329e-05 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.9815\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.9984 - val_loss: 0.3451 - val_accuracy: 0.9815\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.0028e-04 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9815\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.9815\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.3094e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9815\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9815\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.0382e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9852\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.0570e-04 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9852\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.3398e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9852\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.6028e-04 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.9852\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.3367e-04 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.9852\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.9490e-05 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9852\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.3729 - val_accuracy: 0.9815\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 0.3749 - val_accuracy: 0.9815\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.4123e-04 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9815\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.4053e-04 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9815\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.3674 - val_accuracy: 0.9815\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.7699e-04 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9778\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.7443e-04 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9778\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.3776 - val_accuracy: 0.9778\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.8651e-04 - accuracy: 1.0000 - val_loss: 0.3834 - val_accuracy: 0.9778\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.8813e-04 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9778\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5912e-04 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9815\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9815\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.9778\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.8988e-05 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9778\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 0.9984 - val_loss: 0.3898 - val_accuracy: 0.9778\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.9578e-04 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9778\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.3583 - val_accuracy: 0.9778\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 7.8374e-05 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9778\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3.0635e-04 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9815\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9815\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 0.3479 - val_accuracy: 0.9815\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.3190e-04 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9815\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9815\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0187 - accuracy: 0.9968 - val_loss: 0.4007 - val_accuracy: 0.9852\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.4938 - val_accuracy: 0.9741\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.4497 - val_accuracy: 0.9778\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.4315 - val_accuracy: 0.9778\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9952 - val_loss: 0.3955 - val_accuracy: 0.9741\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.9741\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 0.3727 - val_accuracy: 0.9815\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.1672e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9815\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9815\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.4008 - val_accuracy: 0.9815\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0270 - accuracy: 0.9984 - val_loss: 0.3695 - val_accuracy: 0.9815\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 0.9952 - val_loss: 0.3490 - val_accuracy: 0.9852\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9852\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9889\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.3163 - val_accuracy: 0.9852\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9852\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.2939 - val_accuracy: 0.9815\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9815\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 7.0309e-04 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9852\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4.2516e-04 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9852\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3.4270e-04 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.9852\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.2986 - val_accuracy: 0.9852\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 7.7449e-04 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.9852\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.3276 - val_accuracy: 0.9889\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.3506 - val_accuracy: 0.9889\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.3424 - val_accuracy: 0.9852\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.3399 - val_accuracy: 0.9852\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.3369 - val_accuracy: 0.9815\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9815\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9852\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.9852\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9889\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 0.3629 - val_accuracy: 0.9852\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5001e-04 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.9852\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.7607e-04 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9852\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 6.6041e-04 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9852\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 0.3815 - val_accuracy: 0.9852\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.8860e-04 - accuracy: 1.0000 - val_loss: 0.3841 - val_accuracy: 0.9852\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 0.9984 - val_loss: 0.4075 - val_accuracy: 0.9852\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.3763 - val_accuracy: 0.9852\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.3598 - val_accuracy: 0.9852\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.1364e-04 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.9852\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3.7902e-04 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9852\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.9984 - val_loss: 0.3538 - val_accuracy: 0.9852\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.2859e-04 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9852\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 6.0595e-04 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9852\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9852\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5.7951e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9852\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.8296e-04 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.9852\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9852\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9852\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.9112e-04 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9852\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.3120e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9852\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9984 - val_loss: 0.3793 - val_accuracy: 0.9852\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4.7413e-04 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.9852\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.2651e-04 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9852\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9852\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.1521e-04 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9852\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.8748e-04 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9852\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9852\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.1301e-05 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.9852\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2.3328e-04 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.9852\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.5220e-04 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9852\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.3984 - val_accuracy: 0.9852\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.1640e-04 - accuracy: 1.0000 - val_loss: 0.3922 - val_accuracy: 0.9852\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.0910e-04 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9852\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.6596e-04 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9852\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.3878 - val_accuracy: 0.9815\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3821 - val_accuracy: 0.9815\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.7177e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9815\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.4412e-04 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9852\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.9984 - val_loss: 0.3665 - val_accuracy: 0.9852\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.3960 - val_accuracy: 0.9889\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.9669e-04 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9889\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.4407 - val_accuracy: 0.9889\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 6.8607e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9889\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.4172 - val_accuracy: 0.9852\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.4005 - val_accuracy: 0.9852\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9984 - val_loss: 0.3931 - val_accuracy: 0.9852\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9852\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.5989e-04 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9889\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.9889\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6597e-04 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9889\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 6.2876e-05 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9889\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.7912e-04 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9889\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1482e-04 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.9852\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.3980 - val_accuracy: 0.9815\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.1016e-04 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9778\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 0.4308 - val_accuracy: 0.9852\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.1718e-04 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9852\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.1917e-04 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.9852\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4.2347e-04 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.9852\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9984 - val_loss: 0.4192 - val_accuracy: 0.9852\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 8.6147e-04 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.9852\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.3905 - val_accuracy: 0.9852\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9984 - val_loss: 0.3957 - val_accuracy: 0.9852\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9984 - val_loss: 0.3751 - val_accuracy: 0.9852\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.3566 - val_accuracy: 0.9852\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9778\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9968 - val_loss: 0.3474 - val_accuracy: 0.9778\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4.6453e-04 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9778\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9984 - val_loss: 0.3349 - val_accuracy: 0.9778\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 0.9984 - val_loss: 0.3316 - val_accuracy: 0.9815\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.3333 - val_accuracy: 0.9778\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9741\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9778\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9778\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 0.3560 - val_accuracy: 0.9815\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9984 - val_loss: 0.3491 - val_accuracy: 0.9815\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9984 - val_loss: 0.3458 - val_accuracy: 0.9815\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.2683e-04 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.9815\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.3748e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9778\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.3795e-04 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.9778\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.3557 - val_accuracy: 0.9741\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0174 - accuracy: 0.9984 - val_loss: 0.2968 - val_accuracy: 0.9815\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9815\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.3303 - val_accuracy: 0.9815\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.4681e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9815\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 8.5191e-04 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.9815\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.3641 - val_accuracy: 0.9815\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.6661e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9815\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.3328 - val_accuracy: 0.9815\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 0.3252 - val_accuracy: 0.9815\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.3116 - val_accuracy: 0.9815\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.3128 - val_accuracy: 0.9741\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0206 - accuracy: 0.9952 - val_loss: 0.3041 - val_accuracy: 0.9778\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9778\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9778\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.3164 - val_accuracy: 0.9778\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0169 - accuracy: 0.9968 - val_loss: 0.3121 - val_accuracy: 0.9778\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.9778\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.3135 - val_accuracy: 0.9778\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9815\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9852\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9852\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.3489 - val_accuracy: 0.9852\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 0.3592 - val_accuracy: 0.9852\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9852\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.9852\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.8431e-04 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9815\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5.2728e-04 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9815\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9778\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.8154e-04 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9778\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.0930e-04 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9815\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.0629e-04 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9815\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9778\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6002e-04 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9778\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.8350e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9778\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4.1594e-04 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.9778\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4.0384e-04 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9778\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.4098e-04 - accuracy: 1.0000 - val_loss: 0.3744 - val_accuracy: 0.9778\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.3705 - val_accuracy: 0.9815\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.9778\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5000e-04 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9815\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.6552e-04 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.9815\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.7597e-04 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9815\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.9984 - val_loss: 0.3729 - val_accuracy: 0.9815\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.6844e-04 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9778\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.7729e-04 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9815\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3096e-04 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9815\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.4567e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9815\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.1462e-04 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9815\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5885e-04 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9815\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.8227e-04 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9815\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.0880e-04 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.9815\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.6467e-04 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9815\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3164e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9815\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.1814e-05 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9815\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.3908 - val_accuracy: 0.9815\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2.1565e-04 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.9815\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 7.8919e-04 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.9778\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4.6397e-04 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.9815\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.4050 - val_accuracy: 0.9852\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.4073 - val_accuracy: 0.9852\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1534e-04 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9852\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 0.9984 - val_loss: 0.3988 - val_accuracy: 0.9852\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9815\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.3611e-04 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9815\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9815\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.9984 - val_loss: 0.3972 - val_accuracy: 0.9815\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 6.8376e-04 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9852\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.4206e-05 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9852\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 0.9984 - val_loss: 0.4010 - val_accuracy: 0.9815\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4203e-04 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9778\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.8878e-04 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9778\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9778\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.3732e-04 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9815\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9852\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.3929e-04 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9815\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5.8173e-04 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9815\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.2693e-04 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9815\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1011e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9815\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.5568e-04 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9815\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.8416e-04 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9815\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.4096 - val_accuracy: 0.9815\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.3890 - val_accuracy: 0.9815\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.0667e-04 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.9815\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.3452 - val_accuracy: 0.9852\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.2283e-04 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9852\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9889\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.5450e-04 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9852\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4.7278e-04 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9852\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 6.2930e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9726d27c0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the ANN Model \n",
    "#ANN -> Artificial Neural Net \n",
    "\n",
    "#initialize a sequential model \n",
    "model = Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(2, activation='sigmoid'))\n",
    "\n",
    "#compiling \n",
    "model.compile(optimizer='adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "#fitting\n",
    "model.fit(X_train, \n",
    "                y_train, \n",
    "                epochs=500, \n",
    "                batch_size=64, \n",
    "                validation_data=(X_test, y_test),class_weight={0:1,1:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80b0d502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, \n",
    "                       y_test, \n",
    "                      batch_size=16,\n",
    "                      steps=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26d33cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Srikanth_corona.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ac65b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Test=[]\n",
    "for i in y_test:\n",
    "    y_Test.append(i[1])\n",
    "y_Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7541895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict=(np.argmax(model.predict(X_test),axis=1))\n",
    "y_Predict=[]\n",
    "for i in y_predict:\n",
    "    y_Predict.append(i)\n",
    "y_Predict   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c622c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.99      0.99      0.99       135\n",
      "    negative       0.99      0.99      0.99       135\n",
      "\n",
      "    accuracy                           0.99       270\n",
      "   macro avg       0.99      0.99      0.99       270\n",
      "weighted avg       0.99      0.99      0.99       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import seaborn as sns\n",
    "def evaluate_matrix(y_test, y_predict, name):\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    cm_df = pd.DataFrame(cm, index=[\"Positive\",'negative'], columns=[\"Positive\",'negative'])\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "\n",
    "    sns.set(font_scale=1)\n",
    "\n",
    "    ax = sns.heatmap(cm_df, annot=True, square=True, fmt='d', linewidths=.2, cbar=0, cmap=plt.cm.Blues)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "\n",
    "    plt.ylabel(\"True labels\",fontsize = 'x-large')\n",
    "    plt.xlabel(\"Predicted labels\",fontsize = 'x-large')\n",
    "    plt.tight_layout()\n",
    "    plt.title(name,fontsize = 'xx-large',pad = 20)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_Test, y_Predict, target_names=[\"Positive\",'negative']))\n",
    "evaluate_matrix(y_Test, y_Predict,'Evaluate_matrix on Augmented data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715714fe",
   "metadata": {},
   "source": [
    "#### the below part is my rough work, I tested various sounds,that is only for checking various cough sounds, not needed for model bvuilding, ignore if not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3d6bfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#y_pred = model.predict_classes(X_test)\\ny_pred=model.predict(X_test) \\ny_pred=np.argmax(y_pred,axis=1)\\ncm = confusion_matrix(y_test, y_pred)\\ndef plot_confusion_matrix(cm):\\n    plt.figure()\\n    plt.imshow(cm, interpolation=\\'nearest\\', cmap=plt.cm.Blues)\\n    classNames = [\\'Negative\\',\\'Positive\\']\\n    plt.title(\\'COVID-19 Confusion Matrix\\')\\n    plt.ylabel(\\'True label\\')\\n    plt.xlabel(\\'Predicted label\\')\\n    tick_marks = np.arange(len(classNames))\\n    plt.xticks(tick_marks, classNames, rotation=45)\\n    plt.yticks(tick_marks, classNames)\\n    s = [[\\'TN\\',\\'FP\\'], [\\'FN\\', \\'TP\\']]\\n    for i in range(2):\\n        for j in range(2):\\n            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\\n    plt.savefig(\"./img/Fig6_Confusion_Matrix_50_epochs.png\")\\n    plt.show()\\nplot_confusion_matrix(cm)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#y_pred = model.predict_classes(X_test)\n",
    "y_pred=model.predict(X_test) \n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "def plot_confusion_matrix(cm):\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    classNames = ['Negative','Positive']\n",
    "    plt.title('COVID-19 Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.savefig(\"./img/Fig6_Confusion_Matrix_50_epochs.png\")\n",
    "    plt.show()\n",
    "plot_confusion_matrix(cm)'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec510efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def plot_loss_accuracy(clf):\\n    loss_clf = clf.history[\\'loss\\']\\n    acc_clf = clf.history[\\'accuracy\\']\\n    epoch_range = list(range(1, 51))\\n\\n    plt.figure()\\n    plt.plot(epoch_range, loss_clf)\\n    plt.title(f\"Loss for {len(epoch_range)} Epochs\")\\n    plt.xlabel(\"Epochs\")\\n    plt.ylabel(\"Loss\")\\n    plt.savefig(\"./img/Fig4_Loss_Per_50_Epochs.png\")\\n\\n\\n    plt.figure()\\n    plt.plot(epoch_range, acc_clf)\\n    plt.title(f\"Accuracy {len(epoch_range)} Epochs\")\\n    plt.xlabel(\"Epochs\")\\n    plt.ylabel(\"Accuracy\")\\n    plt.savefig(\"./img/Fig5_Accuracy_per_50_epochs.png\")\\n    plt.show()\\n    \\n    y_pred = model.predict_classes(X_test)\\n    print(\"\\n **Confusion Matrix**\\n\")\\n    #print(confusion_matrix(y_test, y_pred))\\n    plot_confusion_matrix(cm)\\n    print(\"\\n **Classification Report**\\n\")\\n    print(classification_report(y_test, y_pred))\\n\\nplot_loss_accuracy(clf)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def plot_loss_accuracy(clf):\n",
    "    loss_clf = clf.history['loss']\n",
    "    acc_clf = clf.history['accuracy']\n",
    "    epoch_range = list(range(1, 51))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epoch_range, loss_clf)\n",
    "    plt.title(f\"Loss for {len(epoch_range)} Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"./img/Fig4_Loss_Per_50_Epochs.png\")\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epoch_range, acc_clf)\n",
    "    plt.title(f\"Accuracy {len(epoch_range)} Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.savefig(\"./img/Fig5_Accuracy_per_50_epochs.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    print(\"\\n **Confusion Matrix**\\n\")\n",
    "    #print(confusion_matrix(y_test, y_pred))\n",
    "    plot_confusion_matrix(cm)\n",
    "    print(\"\\n **Classification Report**\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "plot_loss_accuracy(clf)'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2532be3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing no of values with 0 i.e., not covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa805971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1= (shuffle_train_df.iloc[:, :-1]).to_numpy()\n",
    "X1\n",
    "c=0\n",
    "for i in X1:\n",
    "    i=i.reshape(1,-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    X1=stsc.transform(i)\n",
    "    k=np.argmax(model.predict(X1),axis=1)\n",
    "    \n",
    "    if k==0:\n",
    "        c=c+1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66bff8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 41):\n",
    "    header += f' mfcc{i}'\n",
    "\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15becdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=data['file_properties'][4]\n",
    "def feature_extract(file_name):\n",
    "    y,sr = librosa.load(file_name, mono=True, duration=5)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=40)\n",
    "    to_append = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    return to_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b32e14ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.41269657015800476',\n",
       " '0.05900385230779648',\n",
       " '1555.64863350034',\n",
       " '1418.5999316294915',\n",
       " '2870.7370923913045',\n",
       " '0.13399832589285715',\n",
       " '-340.5880126953125',\n",
       " '104.15670013427734',\n",
       " '-32.22844314575195',\n",
       " '-13.615362167358398',\n",
       " '-3.0296642780303955',\n",
       " '0.512090265750885',\n",
       " '-21.811838150024414',\n",
       " '-17.781814575195312',\n",
       " '-9.270073890686035',\n",
       " '-5.505613803863525',\n",
       " '-5.385944366455078',\n",
       " '-8.24716854095459',\n",
       " '0.9400057792663574',\n",
       " '-5.701087474822998',\n",
       " '-6.326630115509033',\n",
       " '-1.0800398588180542',\n",
       " '-1.8126091957092285',\n",
       " '-2.5189857482910156',\n",
       " '-3.6842663288116455',\n",
       " '-3.564146041870117',\n",
       " '-3.4010818004608154',\n",
       " '-0.5142861008644104',\n",
       " '-1.7463746070861816',\n",
       " '-1.9619994163513184',\n",
       " '-1.5433094501495361',\n",
       " '-0.9622567892074585',\n",
       " '-2.608119487762451',\n",
       " '-2.4753191471099854',\n",
       " '0.0837450698018074',\n",
       " '-1.5333882570266724',\n",
       " '-1.1996523141860962',\n",
       " '-0.1515294909477234',\n",
       " '-1.3328003883361816',\n",
       " '-0.10606633126735687',\n",
       " '0.5825127363204956',\n",
       " '-0.8612028360366821',\n",
       " '0.3206280469894409',\n",
       " '1.5741541385650635',\n",
       " '0.41345855593681335',\n",
       " '0.4446161389350891']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gita=feature_extract(file).split()\n",
    "gita\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "08c24ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc31</th>\n",
       "      <th>mfcc32</th>\n",
       "      <th>mfcc33</th>\n",
       "      <th>mfcc34</th>\n",
       "      <th>mfcc35</th>\n",
       "      <th>mfcc36</th>\n",
       "      <th>mfcc37</th>\n",
       "      <th>mfcc38</th>\n",
       "      <th>mfcc39</th>\n",
       "      <th>mfcc40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.41269657015800476</td>\n",
       "      <td>0.05900385230779648</td>\n",
       "      <td>1555.64863350034</td>\n",
       "      <td>1418.5999316294915</td>\n",
       "      <td>2870.7370923913045</td>\n",
       "      <td>0.13399832589285715</td>\n",
       "      <td>-340.5880126953125</td>\n",
       "      <td>104.15670013427734</td>\n",
       "      <td>-32.22844314575195</td>\n",
       "      <td>-13.615362167358398</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1996523141860962</td>\n",
       "      <td>-0.1515294909477234</td>\n",
       "      <td>-1.3328003883361816</td>\n",
       "      <td>-0.10606633126735687</td>\n",
       "      <td>0.5825127363204956</td>\n",
       "      <td>-0.8612028360366821</td>\n",
       "      <td>0.3206280469894409</td>\n",
       "      <td>1.5741541385650635</td>\n",
       "      <td>0.41345855593681335</td>\n",
       "      <td>0.4446161389350891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           chroma_stft                 rmse spectral_centroid  \\\n",
       "0  0.41269657015800476  0.05900385230779648  1555.64863350034   \n",
       "\n",
       "   spectral_bandwidth             rolloff   zero_crossing_rate  \\\n",
       "0  1418.5999316294915  2870.7370923913045  0.13399832589285715   \n",
       "\n",
       "                mfcc1               mfcc2               mfcc3  \\\n",
       "0  -340.5880126953125  104.15670013427734  -32.22844314575195   \n",
       "\n",
       "                 mfcc4  ...               mfcc31               mfcc32  \\\n",
       "0  -13.615362167358398  ...  -1.1996523141860962  -0.1515294909477234   \n",
       "\n",
       "                mfcc33                mfcc34              mfcc35  \\\n",
       "0  -1.3328003883361816  -0.10606633126735687  0.5825127363204956   \n",
       "\n",
       "                mfcc36              mfcc37              mfcc38  \\\n",
       "0  -0.8612028360366821  0.3206280469894409  1.5741541385650635   \n",
       "\n",
       "                mfcc39              mfcc40  \n",
       "0  0.41345855593681335  0.4446161389350891  \n",
       "\n",
       "[1 rows x 46 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame([gita],columns=header)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "31799ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.41269657015800476', '0.05900385230779648', '1555.64863350034',\n",
       "        '1418.5999316294915', '2870.7370923913045',\n",
       "        '0.13399832589285715', '-340.5880126953125',\n",
       "        '104.15670013427734', '-32.22844314575195',\n",
       "        '-13.615362167358398', '-3.0296642780303955',\n",
       "        '0.512090265750885', '-21.811838150024414',\n",
       "        '-17.781814575195312', '-9.270073890686035',\n",
       "        '-5.505613803863525', '-5.385944366455078', '-8.24716854095459',\n",
       "        '0.9400057792663574', '-5.701087474822998', '-6.326630115509033',\n",
       "        '-1.0800398588180542', '-1.8126091957092285',\n",
       "        '-2.5189857482910156', '-3.6842663288116455',\n",
       "        '-3.564146041870117', '-3.4010818004608154',\n",
       "        '-0.5142861008644104', '-1.7463746070861816',\n",
       "        '-1.9619994163513184', '-1.5433094501495361',\n",
       "        '-0.9622567892074585', '-2.608119487762451',\n",
       "        '-2.4753191471099854', '0.0837450698018074',\n",
       "        '-1.5333882570266724', '-1.1996523141860962',\n",
       "        '-0.1515294909477234', '-1.3328003883361816',\n",
       "        '-0.10606633126735687', '0.5825127363204956',\n",
       "        '-0.8612028360366821', '0.3206280469894409',\n",
       "        '1.5741541385650635', '0.41345855593681335',\n",
       "        '0.4446161389350891']], dtype=object)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = df.to_numpy()\n",
    "X1.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "c2f66418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "X1=stsc.transform(X1)\n",
    "print(np.argmax(model.predict(X1),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "8715f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical,Confuse+report,imbalance(smote),checking with outside data are pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "73e8fffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\Downloads\\\\corona samples\\\\sample-3.wav'"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=r'C:\\Users\\HP\\Downloads\\corona samples'\n",
    "i=3\n",
    "file=path+'\\sample-'+f'{i}'+'.wav'\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "b90f404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,42):\n",
    "    file=path+'\\sample-'+f'{i}'+'.wav'\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 =(df.to_numpy()).reshape(1,-1)\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "fe8749aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "Path=r'C:\\Users\\HP\\Downloads\\normal sounds'\n",
    "for i in range(1,111):\n",
    "    file=Path+'\\sample-'+f'{i}'+'.wav'\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = (df.to_numpy()).reshape(1,-1)\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "3e59c1f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_list=os.listdir(r'C:\\Users\\HP\\Downloads\\COVID')\n",
    "file_list\n",
    "for i in file_list[1:]:\n",
    "    file=os.path.join(r'C:\\Users\\HP\\Downloads\\COVID',i)\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = df.to_numpy()\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "ce398d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/HP/Downloads/trial_covid\\--U7joUcTCo_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-5dCv5_nvU8_ 200.000_ 210.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-bZrDCS8KAg_ 70.000_ 80.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-ej81N6Aqo4_ 0.000_ 8.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-gvLnl1smfs_ 90.000_ 100.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-hu5q-Nn4BM_ 70.000_ 80.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-jLQkyDhIxw_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-jZav58HEOw_ 50.000_ 60.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-Mdd8ysxJ5c_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-o2vmOibWF4_ 310.000_ 320.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-OanE09iAA4_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-szeMToBrRE_ 60.000_ 70.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-TbcaCBA0pI_ 50.000_ 60.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-THYRau6Prs_ 220.000_ 230.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-VbTE2bPuyw_ 210.000_ 220.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-vu4jJkffMw_ 80.000_ 90.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-yJtuj9EuMg_ 190.000_ 200.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\-zeXIY8V1-E_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\05YBpmCnoOQ_ 50.000_ 60.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0AWF9zOT8YY_ 150.000_ 160.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0Dh4NhF27jc_ 140.000_ 150.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0EaxcUhZWe8_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0iiwZ2_9Vi8_ 90.000_ 100.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0MwZQ1-WZyM_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0mZQ6Q-viPw_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0oUkEze_kmo_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0qCvekeAHkc_ 210.000_ 220.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0qktEoIX2Sk_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0QOYirw4e3I_ 270.000_ 280.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0sDlmseq2Kg_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0v8MGxNetjg_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0VaWzVLOWvE_ 120.000_ 130.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\0WPDmbAui6k_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\15lAut5Ry-U_ 70.000_ 80.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\1a1Dx52izTo_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\1e3_ucOz0Ik_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\1F234DLNRYc_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\1j1duoxdxBg_ 70.000_ 80.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\1MSYO4wgiag_ 120.000_ 130.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\1PajbAKd8Kg_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\1UDFq2InljM_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\1Xmw9VUzvLY_ 150.000_ 160.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\1_oZWCKCGqA_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2Bx5e9vwLGk_ 60.000_ 70.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2B_QV_5R4Zo_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2EFjQPMmAS8_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2Ev7_PQ7IIs_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2Ez4R0a1icc_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2hbytlgqDx4_ 140.000_ 150.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2Hp1AvKRiOA_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2I2IzXnhmtc_ 120.000_ 130.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2R3J8pH6E6s_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2sMLoW22TeU_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2TBWSnIjJMk_ 180.000_ 190.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2xURixj6I5k_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2YF-ValJNas_ 0.000_ 5.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\2ZfwEg4JaiU_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\33NSh9cvNvI_ 50.000_ 60.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\39IZIbmQPzA_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\3aFProJmJzY_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\3bas_0f3RG0_ 50.000_ 60.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\3dndmOMZlP8_ 100.000_ 110.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\3Enq7k2IpvQ_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\3fz-0wek44c_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\3gFShyvw8iU_ 70.000_ 80.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\3id3zRRZBVM_ 50.000_ 60.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\3Liy9uBgsQM_ 60.000_ 70.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\3nOZJicBKkU_ 90.000_ 100.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\3vYB7hZxQgA_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\40fIOkLK3j4_ 60.000_ 70.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\42RAaEB-Jgs_ 110.000_ 120.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\43FtU9nHMxc_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\43MaVucRguE_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\44nJyshuBYk_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\46IWQpa2v64_ 90.000_ 100.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4eb2LU3X_zs_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4EiskLYtkO4_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4jQ8ffBxWkk_ 70.000_ 80.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4K946lkrL9U_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4ldID97D-oU_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4lOXjW8rpxU_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4rPNHAf-0Qw_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4txOUgXllWE_ 300.000_ 310.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4vyk0EIJGWY_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4WLF2CT0eCM_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4xQcOwfV48Y_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4yFWcSkby5w_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\4_0uUL2HPe0_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\5hmDPsZnmf4_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\5jznaeFpsJU_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\5l9qTa5OAL8_ 220.000_ 230.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\5r9Ixli8hnc_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\5wbc84KnDS0_ 60.000_ 70.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\60NM10sTc9c_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\64Ymtt704So_ 50.000_ 60.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\6K_sU6-dp0Q_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\6l52kPskdRI_ 350.000_ 360.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\6lbkx_tf50g_ 220.000_ 230.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\6nTcsNoIGDw_ 50.000_ 60.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\6OatUcXF4nk_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\6PdQjCUz-S4_ 260.000_ 270.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\6pyURnYYMwo_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\6uW93XzK0Xw_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\7-MnR3o0iAs_ 120.000_ 130.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\7GBy8CUVUhU_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\7hQ-7sWi8W0_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\7IMXwGU4Ja0_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\7J9eEukmoIA_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\7pqRqXjqeX4_ 330.000_ 340.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\7QkwmMU4w1M_ 220.000_ 230.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\7xSTAmKAsFE_ 120.000_ 130.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\7_v8jFFo9SM_ 50.000_ 60.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\8FEQuq03bgU_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\8FXX56zpypA_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\8ieJbzu7ql8_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\8IhJllXxBlQ_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\8l8ghk2CDbE_ 190.000_ 200.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\8yDeG7e1-9I_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9-XHdlyHhaQ_ 30.000_ 40.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9h3a7fN0f-c_ 240.000_ 250.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9hl4R896W3Y_ 100.000_ 110.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9k1ZuVzpF7c_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9KNqsONT3-Y_ 70.000_ 80.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9kY53W3S_dE_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9P8waFCqbOQ_ 90.000_ 100.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9pX8I7KzQAI_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9WbIa8U8twQ_ 270.000_ 280.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9WNz_rrwLFE_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9xpJWu2rNsY_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9XSE1pdHwSU_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9yAGKsPDM14_ 80.000_ 90.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9Zl4VUruA9I_ 120.000_ 130.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\9_PvnvCyKc8_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cough-heavy-3CwioNQVDBQ6CttLyFVRJpMpVHk2.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cough-heavy-6T43bddKoKfG7MwnJWvrPZSsyrc2.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cough-heavy-hNAGUEhL2Nh7V89at3yFEjQYo6c2.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cough-heavy-hte8VptUoGVFEqvHpbh5brgfcNP2.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cough-heavy-QjBZv868nydJzk0ZzwgKDHSG6Q82.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cough-shallow-3CwioNQVDBQ6CttLyFVRJpMpVHk2.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cough-shallow-6T43bddKoKfG7MwnJWvrPZSsyrc2.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cough-shallow-hNAGUEhL2Nh7V89at3yFEjQYo6c2.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cough-shallow-hte8VptUoGVFEqvHpbh5brgfcNP2.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cough-shallow-QjBZv868nydJzk0ZzwgKDHSG6Q82.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cov1.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\cov2.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\pos-0421-084-cough-m-50.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\pos-0421-086-cough-m-65.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\pos-0421-087-cough-f-40.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\pos-0421-092-cough-m-53.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\pos-0421-093-cough-f-24.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\pos-0421-094-cough-m-51.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\pos-0422-096-cough-m-31.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_-_5kbw2Mcw_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_0WKVY0n8aE_ 150.000_ 160.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_9YKlnmoDjs_ 11.000_ 21.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_AjXY9cHCxA_ 150.000_ 160.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_D3sxdtbFas_ 40.000_ 50.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_dfcXBTcmqU_ 70.000_ 80.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_e4GZ6p6nCY_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_FVreKE6Fj8_ 50.000_ 60.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_HLvqHDclW8_ 210.000_ 220.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_hptdlGvSV4_ 10.000_ 20.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_o5xtnLwtRc_ 0.000_ 10.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_qDSR5skY0c_ 70.000_ 80.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_YqaeNeVQbw_ 20.000_ 30.000.wav\n",
      "C:/Users/HP/Downloads/trial_covid\\_zrAnhgYzSo_ 10.000_ 20.000.wav\n"
     ]
    }
   ],
   "source": [
    "list=os.listdir(r'C:/Users/HP/Downloads/trial_covid')\n",
    "for i in list:\n",
    "    file=os.path.join('C:/Users/HP/Downloads/trial_covid',i)\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "f6f6aa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_properties</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0v8MGxNetjg_ 10.000_ 20.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1j1duoxdxBg_ 70.000_ 80.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MSYO4wgiag_ 120.000_ 130.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1PajbAKd8Kg_ 0.000_ 10.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-jZav58HEOw_ 50.000_ 60.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-bZrDCS8KAg_ 70.000_ 80.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-ej81N6Aqo4_ 0.000_ 8.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-gvLnl1smfs_ 90.000_ 100.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-hu5q-Nn4BM_ 70.000_ 80.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-jLQkyDhIxw_ 10.000_ 20.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_properties      class\n",
       "0      0v8MGxNetjg_ 10.000_ 20.000.wav  not_covid\n",
       "1      1j1duoxdxBg_ 70.000_ 80.000.wav  not_covid\n",
       "2    1MSYO4wgiag_ 120.000_ 130.000.wav  not_covid\n",
       "3       1PajbAKd8Kg_ 0.000_ 10.000.wav  not_covid\n",
       "23     -jZav58HEOw_ 50.000_ 60.000.wav  not_covid\n",
       "..                                 ...        ...\n",
       "165    -bZrDCS8KAg_ 70.000_ 80.000.wav  not_covid\n",
       "166      -ej81N6Aqo4_ 0.000_ 8.000.wav  not_covid\n",
       "167   -gvLnl1smfs_ 90.000_ 100.000.wav  not_covid\n",
       "168    -hu5q-Nn4BM_ 70.000_ 80.000.wav  not_covid\n",
       "169    -jLQkyDhIxw_ 10.000_ 20.000.wav  not_covid\n",
       "\n",
       "[151 rows x 2 columns]"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mf=pd.read_csv(r'Downloads\\cough_trial_extended (1).csv')\n",
    "mfc=mf[mf['class']=='covid']\n",
    "mfn=mf[mf['class']=='not_covid']\n",
    "mfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "b90169ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "route=r'C:/Users/HP/Downloads/trial_covid/'\n",
    "for i in mfn['file_properties']:\n",
    "    file=route+i\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = df.to_numpy()\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "8d6f966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "route=r'C:/Users/HP/Downloads/trial_covid/'\n",
    "for i in mfc['file_properties']:\n",
    "    file=route+i\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = df.to_numpy()\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f0c642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ed8e8aed-6ef6-42ec-88ac-b66993f70591/assets\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-17b0cdd41a63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'web app.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__reduce__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m       return (pickle_utils.deserialize_model_from_bytecode,\n\u001b[1;32m--> 315\u001b[1;33m               pickle_utils.serialize_model_as_bytecode(self))\n\u001b[0m\u001b[0;32m    316\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m       \u001b[1;31m# SavedModel (and hence serialize_model_as_bytecode) only support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\saving\\pickle_utils.py\u001b[0m in \u001b[0;36mserialize_model_as_bytecode\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m           \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTarInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m           \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m           \u001b[0marchive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36msize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;34m\"\"\"Returns the size of the file.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mstat\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    908\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m   \"\"\"\n\u001b[1;32m--> 910\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mstat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mstat_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m   \"\"\"\n\u001b[1;32m--> 926\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_file_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_to_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "file=open('web app.hdf5','wb')\n",
    ".dump(model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b04dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13723ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83703e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314082c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639d82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b121f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530be489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "7a06e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "list=os.listdir(r'C:/Users/HP/Downloads/trial_covid')\n",
    "for i in list:\n",
    "    file=os.path.join('C:/Users/HP/Downloads/trial_covid',i)\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = df.to_numpy()\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "7c8e33ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "path=r'C:\\Users\\HP\\Downloads\\COVID_Cough-master\\data\\negative'\n",
    "list1=os.listdir(path)\n",
    "for i in list1:\n",
    "    file=os.path.join(path,i)\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = df.to_numpy()\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "7076af5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-470-9526c7d5a42b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mgita\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgita\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mX1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-444-d81d021b3ce5>\u001b[0m in \u001b[0;36mfeature_extract\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file_properties'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfeature_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mchroma_stft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoxr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\resampy\\core.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mresample_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path=r'C:\\Users\\HP\\Downloads\\COVID_Cough-master\\data\\positive'\n",
    "list2=os.listdir(path)\n",
    "for i in list2:\n",
    "    file=os.path.join(path,i)\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = (df.to_numpy()).reshape(1,-1)\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "f8994243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7014932"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(l1)#0.9999263\n",
    "min(l1)#0.063761234\n",
    "max(l1)#0.7014932\n",
    "#min(l1)#3.820657e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "75f3a5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2629105\n",
      "0.037541598\n",
      "0.06882894\n",
      "0.11359984\n",
      "0.18278155\n",
      "0.01243481\n",
      "0.6572033\n",
      "0.20930782\n",
      "0.14080727\n",
      "0.29561606\n"
     ]
    }
   ],
   "source": [
    "for i in l:\n",
    "    if i>0.01243481 and i<0.7014932:\n",
    "        print(i)#(0.65,0.012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "21985754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01424998\n",
      "0.016555995\n",
      "0.022710323\n",
      "0.020377576\n",
      "0.016237348\n",
      "0.03887877\n",
      "0.02266112\n"
     ]
    }
   ],
   "source": [
    "for i in l1:\n",
    "    if i>0.01243481 and i<0.7014932:\n",
    "        print(i)#(0.04,0.014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "08f6d676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999902"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(l)#0.9648404\n",
    "min(l)#6.727416e-07\n",
    "max(l)#0.9999902\n",
    "#min(l)#0.01243481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "c34c469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "path=r'D:\\webm to wav\\corona'\n",
    "list3=os.listdir(path)\n",
    "for i in list3:\n",
    "    file=os.path.join(path,i)\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = (df.to_numpy()).reshape(1,-1)\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "bab67103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "path=r'D:\\webm to wav\\normal'\n",
    "list4=os.listdir(path)\n",
    "for i in list4:\n",
    "    file=os.path.join(path,i)\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = (df.to_numpy()).reshape(1,-1)\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "b669b441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "path=r'C:\\Users\\HP\\Downloads\\NORMAL S'\n",
    "list5=os.listdir(path)\n",
    "for i in list5:\n",
    "    file=os.path.join(path,i)\n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = (df.to_numpy()).reshape(1,-1)\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e614d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "of=pd.read_csv(r'C:\\Users\\HP\\Downloads\\XAI Covid-19 Cough\\covid.csv')\n",
    "of1=of[of['classification']=='covid']\n",
    "of2=of[of['classification']=='not_covid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171a208f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_extract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f9c3a5d7acb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#print(file)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mgita\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgita\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mX1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_extract' is not defined"
     ]
    }
   ],
   "source": [
    "path=r'C:\\Users\\HP\\Downloads\\XAI Covid-19 Cough\\audios_covid'\n",
    "import os\n",
    "for i in of2['file_name']:\n",
    "    file=os.path.join(path,i)\n",
    "    file=file+'.wav'\n",
    "    #print(file)\n",
    "    \n",
    "    gita=feature_extract(file).split()\n",
    "    df=pd.DataFrame([gita],columns=header)\n",
    "    X1 = (df.to_numpy()).reshape(1,-1)\n",
    "    X1=stsc.transform(X1)\n",
    "    print(np.argmax(model.predict(X1),axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf0f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
